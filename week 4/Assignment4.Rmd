---
title: "COS-D419 Factor Analysis and Structural Equation Models 2023, Assignment 4"
author: "Rong Guang"
date: "`r Sys.Date()`"
output: 
  bookdown::pdf_document2:
    latex_engine: lualatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)
```

# SEM & teacher burnout

## Exercise 4.1

Draw the graph of the initial, full structural equation model. Make sure that you have included all the specified paths.

Estimate the initial model using the robust MLM estimator *(robust variant of the ML estimator, to be precise!)* and present a brief summary of the model fit.

# Preparation

## Read in the data set

Start by downloading the data file from Moodle to Project folder.

```{r}
library(tidyverse)
library(readr)
library(here)

#This week's file name
latest.name <- "ALLSEC.CSV"

#read in the data
mbi <- read_csv(file.path(here(), 
                'data',
                latest.name))
```

## Write functions

To control length of reports, codes already shown in the previous homework were not showing in the current report. Yet they are available in .rmd report.

### to check unique values

```{r, echo = F}
unique.levels <-  function(sc){
  values <- lapply(sc, function(x)sort(unique(x))) 
for(x in 1:ncol(sc)){
  a <- paste(c("Variable ", 
               names(values)[x], 
               " has values of ", 
               paste(values[[x]], 
                     collapse = ",")), 
             collapse = "")
  print(a)
  }
}
```

### to generate CFA results with improved readability

```{r, echo = F}
#goodness of fit indicators for ml
sem.summary.ml.a <- function(fit, fa.num, item.num, estimator){
  options(scipen = 999)
  cfa.measure <- fitMeasures(fit,    #obtain specified measured.
                            c("chisq", 
                              "df", 
                              "pvalue", 
                              "cfi", 
                              "tli",
                              "rmsea",
                              "rmsea.pvalue",
                              "srmr",
                              "chisq.scaling.factor")) 
  names(cfa.measure) <- c("chi square", "df", "p value", "CFI", "TLI", "RMSEA", "RMSEA p value", "SRMR")
  #turn named vector to data frame
sem.tab.a <- cfa.measure %>%  
  tibble(name= names(cfa.measure), value = cfa.measure) %>% # vector to df
  select(Measure = name, Value = value) %>%  #select and rename columns
  mutate(Value = round(as.numeric(Value),3)) %>%  # round
  kable(format = "markdown",   # table aesthetics 
        booktabs = T, #Latex booktabs
        caption =  #caption
          paste("Goodness-of-fit and subjective indices of fit for", fa.num, "factor model ", estimator)) %>%
  kable_styling(latex_options = "striped") %>% # gray every other row
  row_spec(0, background = "#9999CC")
 cfa.tab.a
}

#goodness of fit indicators for mlm
sem.summary.mlm.a <- function(fit, fa.num, item.num, estimator,title){
  options(scipen = 999)
  cfa.measure <- fitMeasures(fit,    #obtain specified measured.
                            c("chisq.scaled", 
                              "df.scaled", 
                              "pvalue.scaled", 
                              "cfi.scaled", 
                              "tli.scaled",
                              "rmsea.scaled",
                              "rmsea.pvalue.scaled",
                              "srmr_bentler",
                              "chisq.scaling.factor")) 
  names(cfa.measure) <- c("chi square", "df", "p value", "CFI", "TLI", "RMSEA", "RMSEA p value", "SRMR", "CSF")
  #turn named vector to data frame
cfa.tab.a <- cfa.measure %>%  
  tibble(name= names(cfa.measure), value = cfa.measure) %>% # vector to df
  select(Measure = name, Value = value) %>%  #select and rename columns
  mutate(Value = round(as.numeric(Value),3)) %>%  # round
  kable(format = "markdown",   # table aesthetics 
        booktabs = T, #Latex booktabs
        caption =  #caption
         title) %>%
  kable_styling(latex_options = "striped") %>% # gray every other row
  row_spec(0, background = "#9999CC")
 cfa.tab.a
}

#factor loading
sem.summary.b <- function(fit, fa.num, item.num, estimator){
  options(scipen = 999)
  #factor loading
  cfa.tab.b <- parameterEstimates(fit, standardized=TRUE) %>% # obtain estimates
  filter(op == "=~") %>%  #select "is measured by" rows
  select('Latent Factor'=lhs, #left hand side column
         Indicator=rhs, #right hand side column
         B=est, #estimates
         SE=se, #standard error
         Z=z, #z statistics
         'p-value'=pvalue, #p value
         Beta=std.all) %>%  
  kable(digits = 3, #rounded to 3
        format="markdown", #Latex markdown
        booktabs=TRUE, #Latex booktabs
        caption=paste("Factor Loadings for",fa.num,"factor CFA model estimated by ", estimator)) %>% #caption
  kable_styling(latex_options = "striped") %>% #gray every other row
  row_spec(0, background = "#9999CC") # color the first row
  cfa.tab.b
  }

#Variance
sem.summary.c <- function(fit, fa.num, item.num, estimator){
  options(scipen = 999)
  #Variance
  type <- rep(c("Residual variance", "Total variance"), 
            time = c(item.num, fa.num)) #create a new row clarifying types of variance

variance <- parameterEstimates(fit, standardized=TRUE) %>% #obtain estimates
  filter(op == "~~") #select "is correlated with" rows
variance <- variance[1:sum(item.num,fa.num),] #subset 1:18 rows (variance row)
variance <- cbind(type, variance) #add column
cfa.tab.c <- variance %>%select(Type = type, #select and rename variables
                   Indicator=rhs, #right hand side column
                   B=est, #estimates
                   SE=se,#standard error
                   Z=z, #z statistics
                   'p-value'=pvalue, #p value
                   Beta=std.all) %>% 
  kable(digits = 3, #rounded
        format="markdown",  #Latex markdown
        booktabs=TRUE, #Latex booktabs
        caption=paste("Variances for", fa.num, "factor model estimated by ", estimator)) %>% #caption
  kable_styling(latex_options = "striped") %>% # gray every other row
  row_spec(0, background = "#9999CC") # color the variable row
  cfa.tab.c
}

#Covariance
sem.summary.d <- function(fit, fa.num, item.num, estimator){
  options(scipen = 999)
  #covariance
  variance <- parameterEstimates(fit, standardized=TRUE) %>%
  filter(op == "~~")
  covar.num = (fa.num+(fa.num-1))/2
variance <- variance[sum(item.num,fa.num,1):sum(item.num,fa.num,covar.num),]
type <- paste(variance$lhs, "with", variance$rhs) 
variance <- cbind(type, variance)
rownames(variance) <- NULL
cfa.tab.d <- variance %>%select(Type=type, 
                   B=est, 
                   SE=se,
                   Z=z, 
                   'p-value'=pvalue, 
                   Beta=std.all) %>% 
  kable(digits = 3, 
        format="markdown", 
        booktabs=TRUE, 
        caption=paste("Covariances for", fa.num, 
                      "factor model estimated by ", 
                      estimator)) %>% 
  kable_styling(latex_options = "striped") %>% 
  row_spec(0, background = "#9999CC")
  cfa.tab.d
}

```

### to generate functions for improving aethetics of correlation matrix 

```{r, echo = F}
library(GGally)
my.fun.density <- function(data, mapping, ...) { #notes are roughly same with above

    ggplot(data = data, mapping = mapping) +
       geom_histogram(aes(y=..density..),
                      color = "black", 
                      fill = "white")+
       geom_density(fill = "#FF6666", alpha = 0.25) +
       theme(panel.grid.major = element_blank(), 
             panel.grid.minor = element_blank(),
             panel.background = element_rect(fill = "#9999CC",
                                             color = "black"))
} 

#define a function that allows me to fine-tune the matrix
my.fun.smooth <- function(data,    #my function needs 3 arguments
                          mapping,
                          method = "loess"){
  ggplot(data = data, #data is passed from ggpairs' arguments
         mapping = mapping)+#aes is passed from ggpairs' arguments
           geom_point(size = 0.3,  #draw points
                      color = "blue")+
           geom_smooth(method = method,  #fit a linear regression
                       size = 0.3, 
                       color = "red")+
           theme(panel.grid.major = element_blank(), #get rid of the grids
                 panel.grid.minor = element_blank(),
                 panel.background = element_rect(fill = "#F0E442", #adjust background
                                                 color = "black"))
} 

```

### to generate a function for histogram overlapping with density plot

```{r, echo = F}
corr.density <- function(data, fig.num = 1){
  data %>% 
  pivot_longer(everything()) %>%  #longer format
  ggplot(aes(x = value)) + #x axis used variable "value" (a default of pivot)
  geom_histogram(binwidth = 1, aes(y = ..density..), #match ys of density and histogram plots
                 color = "black",  fill = "#9999CC")+  # adjust aesthetics for hist
  geom_density(fill = "pink", alpha = 0.25)+ #adjust aesthetics for density plot
  facet_wrap(~name, scales = "free", ncol =4) + #wrap by name variable
  theme(panel.grid.major = element_blank(), #get rid of the  grids
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white",#adjust the background
                                        color = "black"),
        strip.background = element_rect(color = "black",#adjust the strips aes
                                        fill = "steelblue"),
        strip.text = element_text(size =8, color = "white"), #adjust strip text
        axis.title.x = element_text(size = 3), #adjust the x text
        axis.title.y = element_text(size = 3), # adjust the y text
        plot.title = element_text(size = 12, 
                                  face = "bold",
                                  hjust = 0.5))+ #adjust the title
  labs(title = paste("Figure", fig.num," Distribution of selected items")) #title it
  }

```

### to generate a function for violin overlapping with box plot

```{r, echo = F}
violin.box <- function(data, fig.num = 2){
  mbi.long <- data %>% pivot_longer(everything(), names_to = "item", values_to = "score")

mbi.long %>% 
  ggplot(aes(x = item, y = score)) +
  geom_violin(trim=F, fill = "#9999CC") +
  theme(legend.position = "none", 
        axis.text.x = element_text(angle = 45, hjust =1),
        axis.title = element_text(size = 12),
        panel.background = element_rect(fill = "white", color = "black"),
        plot.title = element_text(face="bold",
                                  hjust = 0.5),
        axis.title.x = element_blank())+
  labs(x = "Item", 
       y = "Score",
       title = paste("Figureou", fig.num, " Violin plot of the selected items"))+
  geom_boxplot(width = 0.1, fill = "white")
}
```

### To generate a function describing continuous data set

```{r, echo=F}
descriptive <- function(data){
  library(finalfit)
library(kableExtra)
inspect.table <- ff_glimpse(data)$Continuous
inspect.table$label <- NULL
inspect.table %>% 
  mutate('Q1Q3' = paste(quartile_25, 
                        quartile_75, 
                        sep = " ~ ")) %>% 
  select(n, 
         'n of NA' = missing_n, 
         'Mean' = mean, 
         'Median' = median,
         'SD' = sd, 
         'Min' = min, 
         'Max' = max,
         'Q1~Q3' = Q1Q3) %>%
  kable(booktabs = T,  
        align = "r",
        longtable = T,
        linesep = "",
        caption = "Descriptive statistics for measurements") %>% 
  add_header_above(c(" ", 
                     " " = 2,
                     "Central tendency" = 2, 
                     "Dispersion tendency" = 4)) %>% 
  kable_styling(latex_options = c("striped", 
                                  "repeat_header")) %>% 
  column_spec(1, width = "3cm")
}
```

## Inspect the data

### Data structure

Have a quick overview of the data structure

```{r}
library(knitr)
library(broom)
dim(mbi);mbi %>% apply(2, function(x)class(x));
```

The data set contains 22 numeric variables of 372 obs. Their values appear to follow a consistent pattern covering the integer from 1 to 7, except for Items 4, 7, 17 and 21, which did not include a value of 1. 

### Descriptive statistics of measured variables

```{r}
library(finalfit);library(kableExtra);

descriptive(mbi) |> 
  pack_rows(index = 
              c("Factor 1*: Role Ambiguity \n(high score means negative)" = 2, 
                "Factor 2*: Role conflict \n(high score means negative)" = 2, 
                "Factor 3*: Work overload \n(high score means negative)" = 2,
                "Factor 4‡: classroom climate" = 4,
                "Factor 5*: Decision-making" = 2, 
                "Factor 6*: Superior support" =  2, 
                "Factor 7*: Peer support" = 2,
                "Factor 8‡: Self-esteem" = 3, 
                "Factor 9‡: External locus of control" = 5,
                "Factor 10†: Emotional Exhaustion \n(high score means negative)" = 3, 
                "Factor 11†: Depersonalization \n(high score means negative)" = 2, 
                "Factor 12†: Personal Accomplishment" = 3)) |> 
  footnote(general = 
             "Indicators variables were formulated through item parcels.",
    symbol = c("These indicators are parcels from Teacher Stress Scale instrument",
               "These indicators are parcels from BMI instrument",
               "These parcels consist of items from single unidimensional scales")
           )
```

### Visualization

(1) Histogram

Distribution of the data was examined via Histogram

```{r, fig.width = 7, fig.height=10, warning = F, message=F}
corr.density(mbi, fig.num = 1)
```

Ridge-line plots were generated for TSS and MBI indicators, respectively. By partially overlaying, it is a demonstration viable for comparing multiple distributions.  

```{r, fig.height = 7, fig.width=8, warning = F, message=F}
library(ggridges)
library(viridis)
library(hrbrthemes)
library(patchwork)
a <- mbi |> 
  select(
    starts_with("EE")|starts_with("DP")|starts_with("PA")
    ) |> 
  pivot_longer(everything(), names_to = "variable", values_to = "value") |> 
  ggplot(aes(x = value, y = variable, fill = ..x..)) +
  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +
  scale_fill_viridis(name = "parcelled score", option = "C") +
  labs(title = 
         'Fig2 (a). Distribution of indicator scores from BMI instrument') +
  labs(x = "Indicator scores", y = "Indicators") +
    theme(
      legend.position="none",
      panel.spacing = unit(0.1, "lines"),
      plot.title = element_text(size = 12),
      panel.grid.major = element_blank(),
      panel.background = element_rect(color = "black",
                                      fill = "white")
      )

b <- mbi |> 
  select(
    starts_with("ROL")|starts_with("WOR")|starts_with("DEC")|contains("SUP")
    ) |> 
  pivot_longer(everything(), names_to = "variable", values_to = "value") |> 
  ggplot(aes(x = value, y = variable, fill = ..x..)) +
  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +
  scale_fill_viridis(name = "parcelled score", option = "C") +
  labs(title = 
         'Fig2 (b). Distribution of indicator scores from TSS instrument') +
  labs(x = "Indicator scores", y = "Indicators")+
    theme(
      legend.position="none",
      panel.spacing = unit(0.1, "lines"),
      plot.title = element_text(size = 12),
      panel.grid.major = element_blank(),
      panel.background = element_rect(color = "black",
                                      fill = "white")
    )

a/b
```

Clearly, within each instrument, indicators for same factor tend to show similar distribution features. 

(2) Violin plot

Violin plot also provides information on distribution, plus ideas on out-liers.

```{r fig.width=10, fig.height=6}
a <- mbi |> 
  select(1:16) |> 
  violin.box(fig.num = "3(a)")

b <- mbi |> 
  select(17:32) |> 
  violin.box(fig.num = "3(b)")
library(patchwork)
a/b
```

(3) Correlation among items

```{r, fig.width = 7, fig.height=7}
#draw it
mbi |>  select(starts_with("EE")|starts_with("DP")|starts_with("PA")) |> 
  ggpairs(lower = 
          list(continuous = my.fun.smooth), #lower half show points with fitted line
        diag =
          list(continuous = my.fun.density), #diagonal grids show density plots
        title = "Fig4(a). Relationships among parcels of MBI instrument") + #title
  theme (plot.title = element_text(size = 12,  #adjust title visuals
                                   face = "bold")) 
```

```{r, fig.width = 9, fig.height=9}
mbi |>  select(starts_with("ROL")|starts_with("WOR")|starts_with("DEC")|contains("SUP")) |> 
  ggpairs(lower = 
          list(continuous = my.fun.smooth), #lower half show points with fitted line
        diag =
          list(continuous = my.fun.density), #diagonal grids show density plots
        title = "Fig4(b). Relationships among parcels of TSS instrument") + #title
  theme (plot.title = element_text(size = 14,  #adjust title visuals
                                   face = "bold")) 
```

# Testing the for the validity of causal structure of burnout

## Initial full structural equation model (hypothesized model modified according to CFA)

This full structural equation model was a hypothesized model. I have established causal structure linking several stressor variables considered to contribute to the presence of burnout (Fig. 4). These postulated causal relations linking variables were supported in theory and/or empirical research. I wanted to test the hypothesis that the causal pattern was true. The findings would contribute to the understanding of key determinants of teacher burnout. Since the hypothesis was proven not true, I performed post-hoc analysis to improve the causal structure step by step, until best fitting, albeit most parsimonious, model of any set of tested models had been achieved. 

Note that *"an important preliminary step in the analysis of full latent variable models is to test first for the validity of the measurement model before making any attempt to evaluate the structural model. Accordingly, CFA procedures are used in testing the validity of the indicator variables. Once it is known that the measurement model is operating adequately, one can then have more confidence in findings related to assessment of the hypothesized structural model."* The current analysis started at the point where CFA had already been done. As described by Byrne, the analysis produced fit indices showing exceptionally good fit to the data; nonetheless, CFA model for the TSS was re-specified to include two additional parameters, both about allowing for cross-loading terms (DEC2 cross-loads onto Factor 1; DEC2 cross-loads onto Factor 5). These parameters set free were incorporated into the initial hypothesized model (Fig. 4).  
### Define the initial model

```{r, fig.height =  16, fig.width = 28}
library(semPlot)#install.packages("semPlot")

initial_model <- '
# Factors:
 F1ROLA =~ ROLEA1 + ROLEA2 + DEC2
 F2ROLC =~ ROLEC1 + ROLEC2
 F3WORK =~ WORK1 + WORK2
 F4CLIM =~ CCLIM1 + CCLIM2 + CCLIM3 + CCLIM4
 F5DEC =~ DEC1 + DEC2
 F6SSUP =~ SSUP1 + SSUP2 + DEC2
 F7PSUP =~ PSUP1 + PSUP2
 F8SELF =~ SELF1 + SELF2 + SELF3
 F9ELC =~ ELC1 + ELC2 + ELC3 + ELC4 + ELC5
 F10EE =~ EE1 + EE2 + EE3
 F11DP =~ DP1 + DP2
 F12PA =~ PA1 + PA2 + PA3
# Regressions:
 F8SELF ~ F5DEC + F6SSUP + F7PSUP
 F9ELC ~ F5DEC
 F10EE ~ F2ROLC + F3WORK + F4CLIM
 F11DP ~ F2ROLC + F10EE
 F12PA ~ F1ROLA + F8SELF + F9ELC + F10EE + F11DP
'
```

### Visualize the initial model

To approximate the visual effect on slides, the coordinates for each nodes were defined on a 60 by 72 matrix.

```{r}
#generate a matrix
m <- matrix(NA, 60, 72)

#define positions of the factors
m[12, 68] <- "F1ROLA"
m[12, 40] <- "F2ROLC"
m[12, 28] <- "F3WORK"
m[12,12] <- "F4CLIM"
m[21,12] <-"F5DEC"
m[40,12] <-"F6SSUP"
m[53,9] <-"F7PSUP"
m[44,24] <-"F8SELF" 
m[52,40] <-"F9ELC"
m[37,48] <-"F10EE"
m[26,60] <-"F11DP"
m[48,64] <-"F12PA"

#define the posiitions of the indicators (parcelled items)
m[4, 72] <- "ROLEA1"
m[4, 64] <- "ROLEA2"
m[4, 48] <- "ROLEC1"
m[4, 40] <- "ROLEC2"
m[4, 32] <- "WORK1"
m[4, 24] <- "WORK2"
m[4, 16] <- "CCLIM1"
m[5, 10] <- "CCLIM2"
m[10, 4] <- "CCLIM3"
m[15, 4] <- "CCLIM4"
m[20, 4] <- "DEC1"
m[27, 6] <- "DEC2"
m[36, 4] <- "SSUP1"
m[40, 4] <- "SSUP2"
m[59, 6] <- "PSUP1"
m[59, 13] <- "PSUP2"
m[48, 32] <- "SELF1"
m[52, 28] <- "SELF2"
m[51, 21] <- "SELF3"
m[56, 50] <- "ELC1"
m[60, 48] <- "ELC2"
m[60, 42] <- "ELC3"
m[60, 35] <- "ELC4"
m[56, 31] <- "ELC5"
m[43, 45] <- "EE1"
m[39, 40] <- "EE2"
m[35, 38] <- "EE3"
m[20, 64] <- "DP1"  
m[20, 58] <- "DP2"
m[52, 71] <- "PA1"
m[56, 64] <- "PA2"
m[53, 57] <- "PA3"
```

The diagram of the inital model was generated. 

```{r, fig.height =  10, fig.width = 14}
semPaths(semPlotModel(initial_model),
             style = "lisrel",
             rotation = 2,
             sizeLat = 6, 
             sizeLat2 = 5,
             sizeMan = 5,
             sizeMan2 = 2,
             residScale = 4,
             shapeMan = "rectangle",
             edge.color = c(rep("black",34),
                            rep("blue",14),
                            rep("gray",32),
                            rep("red",5)),
         residuals = T,
         layout = m,
         nCharNodes=0,
         optimizeLatRes = T,
         exoVar = F)
title(main = list("Figure 5. Hypothesized model of teacher burnout", 
                  cex = 1.5, font =1),
     outer = F, line = -1)
title(sub = "Notes: Red arrow indicates factor residuals; gray arrow indicates error residuals; 
     blue arrow indicates regression path; black arrow indicates factor loading", 
     line = 0, adj = 0.7)
```

### Estimate the SEM model (initial)

```{r}
library(lavaan)
model1 <- initial_model # defined above

# Estimate the model with the robust (MLM) estimator:
sem1 <- sem(model1, data = mbi, estimator = "MLM", mimic = "Mplus")

# Numerical summary of the model:
sem.summary.mlm.a(sem1, 12, 32, "mlm", "Model fit indices for initial model")
#summary(sem1, fit.measures = TRUE, standardized = TRUE)
```


```{r}
options(scipen = 999)
#regression path estimates
sem.parameter <- parameterEstimates(sem1, standardized=TRUE) |>  # obtain estimates
  filter(op == "~") |>   #select "is measured by" rows
  select('DV*'=lhs, #left hand side column
         'IV*'=rhs, #right hand side column
         'B†'=est, #estimates
         'Beta‡'=std.all,#estimates standardized
         SE=se, #standard error
         Z=z, #z statistics
         'p-value'=pvalue #p value
         )

#round the p-value column
sem.parameter$`p-value` <- sem.parameter$`p-value` |> 
  round(3)

#add a conditional logic to the p-value column that >0.05 cell shows in red
sem.parameter$`p-value` <- cell_spec(sem.parameter$`p-value`, 
                                     color = ifelse(
                                       sem.parameter$`p-value` > 0.05, 
                                       "red", 
                                       "black")
                                     )
#furhter aesthetics 
sem.parameter |> 
  kable(digits = 3, #rounded to 3
        #format="latex", #Latex markdown
        booktabs=TRUE, #Latex booktabs
        linesep = "",
        caption= "Structural regression path and residual variance estimates.",
        escape = F) %>% #caption
  kable_styling(latex_options = "striped") %>% #gray every other row
  footnote(general = "Rows in bold have insignificant parameters.",
           symbol = c("DV: dependent variable; IV: independent variable",
                      "Crude estimates",
                      "Standardized estimates"))
```


```{r}
#Variance
type <- "Total variance" #create a new row clarifying types of variance
#write a function for minus calculation
minus <- function(x,y) {x - y}

variance <- parameterEstimates(sem1, standardized=TRUE)  |>  #obtain estimates
  filter(op == "~~") #select "is correlated with" rows
variance <- variance[minus(sum(32,12), 5):sum(32,12),] #subset needed rows (variance row)
variance <- cbind(type, variance) #add column
sem.tab.variance <- variance %>%select(Type = type, #select and rename variables
                   Factor=rhs, #right hand side column
                   'B*'=est, #estimates
                   'Beta†'=std.all, #standardized estimates
                   SE=se,#standard error
                   Z=z, #z statistics
                   'p-value'=pvalue #p value
                   )  
#remove the row names
rownames(sem.tab.variance) <- NULL

#round the p-value column
sem.tab.variance$`B*` <- sem.tab.variance$`B*` |> 
  round(3)

#add a conditional logic to the p-value column that >0.05 cell shows in red
sem.tab.variance$`B*` <- cell_spec(sem.tab.variance$`B*`, 
                                     color = ifelse(
                                       sem.tab.variance$`B*` < 0, 
                                       "red", 
                                       "black")
                                     )

sem.tab.variance |> 
  kable(digits = 3, #rounded
        #format="markdown",  #Latex markdown
        booktabs=TRUE, #Latex booktabs
        caption=
          "Residual variance of the dependent variables for initial model",
        escape = F) |>  #caption
  kable_styling(latex_options = "striped") |>    # gray every other row
  footnote(general = 
             "Negative crude residual variance will be highlighted in red",
           symbol = c("Crude estimates",
                      "Standardized estimates"))
```

### Comments on the result (initial model)

Here we see that the rescaled χ2 value (i.e., the MLM χ2) is 1541.844 with 427 degrees of freedom. The reported chi square scaling factor value for the MLM estimator indicates that if the MLM χ2 were multiplied by 1.127, it would approximate the uncorrected ML χ2 value (1737.658).

Given the large number of parameters estimated in this model, the reported results are understandably lengthy. Thus, in the interest of space, I report findings pertinent to only the structural parameters, as well as a few residual variances. These results are presented in Table 3 and 4.

Examination of estimated parameters in the model revealed all to be statistically significant except for those highlighted in red in Figure 3. These non-significant parameters the following structural regression paths: (a) F10 on F2 (Role Conflict → Emotional Exhaustion), F10 on F3 (Work Overload → Emotional Exhaustion), F10 on F4 (Classroom Climate → Emotional Exhaustion), and (b) F12 on F1 (Role Ambiguity → Personal Accomplishment). 

For the negative variance for the residual associated with Factor 10 (highlighted in red in table 4), I left it as it was for the time being.

### Model mis-specification

A review of the MIs reveals some evidence of misfit in the model. Because we are interested solely in the causal paths of the model at this point, only MIs related to these parameters are included in

```{r}
#extract needed variables
MI.model1 <- modindices(sem1, 
                  standardized = TRUE, 
                  sort. = TRUE, 
                  maximum.number = 20) |> 
  filter(op == "~") |> 
  filter(lhs %in%  #When these factors are predicted variables, it is related
           c("F8SELF",  # to the topic of this study
             "F9ELC", 
             "F10EE", 
             "F11DP", 
             "F12PA")) 

#adapt to publication style
MI.model1 <- MI.model1 |> 
  mutate(Parameter = paste(rhs, "→", lhs)) |> 
  select(Parameter, MI = mi, EPC = epc, "std EPC" = sepc.all) |> 
  filter(MI>10) |> 
  mutate("Logics" = c("Sensible and meaningful",
                      "illogical (wrong direction of correlation)",
                      "Sensibe but not meaningful for this study"))

#add footnote symbol to parameters
  for (i in 1:nrow(MI.model1)){
  symbol <- c("*", "†", "‡") 
  Parameter <- unlist(MI.model1$Parameter)
  MI.model1$Parameter[i] <-  paste0(Parameter[i], symbol[i])
  }

#Visualize the table
MI.model1 |> 
  kable(digits = 3,
        booktab = T,
        linesep = "",
        caption = "Select modification indices for initial model") |> 
  kable_styling(latex_options = "striped") |> 
  row_spec(1, color = "red") |> 
  footnote(general = 
             "Parameter highlighted in red is selected for modification",
    symbol = c("Poorer Classroom climate leads to worsening depersonalization",
             "Less workload leads to worsening depersonalization",
             "Higher accomplishment results in increased self-esteem"))
```



## Post hos analysis (Model 2)

### Compare SEM model 2 with initial model

I defined model 2 as per the conclusion from last section: set the regression path leading from F4 to F11 (Poorer Classroom climate leads to worsening depersonalization) free to estimate (Fig 6). The model fit indice comparison between the current model (model2) and the initial model was tabulated in table . 

```{r}
model2 <- paste(initial_model, "F11DP ~ F4CLIM")

# Estimate the model with the robust (MLM) estimator:
sem2 <- sem(model2, data = mbi, estimator = "MLM", mimic = "Mplus")

# Numerical summary of the model:
sem.summary.mlm.a(sem2, 12, 32, "mlm", "Model fit indices for model 2") |> 
  unlist()

```

A function for calculating χ2 difference was defined. 

```{r}
chi.diff <- function(sem1, sem2){
  measure0 <- fitMeasures(sem1, 
                          c("df.scaled", 
                            "chisq.scaling.factor", 
                            "chisq.scaled")) |> 
    as.vector()
  measure1 <- fitMeasures(sem2, 
                          c("df.scaled", 
                            "chisq.scaling.factor", 
                            "chisq.scaled")) |>
    as.vector()
  cd <- 
    (measure0[1]*measure0[2]-measure1[1]*measure1[2])/(measure0[1]-measure1[1])
  TRd <-
    (measure0[3]*measure0[2]-measure1[3]*measure1[2])/cd 
  TRd <- TRd |> round(3)
  print(TRd)
}

```


```{r}
#extract needed fit indices in model1
sem.measure1 <- fitMeasures(sem1,    #obtain specified measured.
                            c("chisq.scaled", 
                              "df.scaled", 
                              "pvalue.scaled", 
                              "cfi.scaled", 
                              "tli.scaled",
                              "rmsea.scaled",
                              "srmr_bentler",
                              "chisq.scaling.factor")) |> 
  t() |> 
  round(3)
#extract needed fit indices in model2
sem.measure2 <- fitMeasures(sem2,    #obtain specified measured.
                            c("chisq.scaled", 
                              "df.scaled", 
                              "pvalue.scaled", 
                              "cfi.scaled", 
                              "tli.scaled",
                              "rmsea.scaled",
                              "srmr_bentler",
                              "chisq.scaling.factor")) |> 
  t() |> 
  round(3)
#combine the 2 sets of indices 
sem.compare2 <- rbind(sem.measure1, sem.measure2) |> data.frame()

#add column names
colnames(sem.compare2) <- c("χ2", "DF", "p value", "CFI", "TLI", 
                            "RMSEA", "SRMR", "CSF")
#turn named vector to data frame
sem.compare2.tab<- sem.compare2 %>% 
  mutate("Δχ2" = chi.diff(sem1, sem2)) |> 
  select("χ2", "DF", "p value", "Δχ2", "CFI", "TLI", "RMSEA", "SRMR", "CSF") 

sem.compare2.tab[1,4] <- "--"
rownames(sem.compare2.tab) <- c("model1", "model2*")  

sem.compare2.tab |> 
  kable(booktab =T,
        #format = "markdown",
        caption = "Comparison of new and preceding models",
        align = "r") |> 
  kable_styling() |> 
  footnote(symbol = "Model1 + parameter 'F4→F11' set free to estimate")
```


```{r, fig.height =  10, fig.width = 14}
semPaths(semPlotModel(model2),
             style = "lisrel",
             rotation = 2,
             sizeLat = 6, 
             sizeLat2 = 5,
             sizeMan = 5,
             sizeMan2 = 2,
             residScale = 4,
             shapeMan = "rectangle",
             edge.color = c(rep("black",34),
                            rep("blue",14),
                            "orange",
                            rep("gray",32),
                            rep("red",5)),
         residuals = T,
         layout = m,
         nCharNodes=0,
         optimizeLatRes = T,
         exoVar = F)
title(main = list("Figure 6. Modified model (Model 2) of teacher burnout",
                  cex = 1.5, font =1),
     outer = F, line = -1)
title(sub = 
        "Notes: Orange arrow is the regression path set free to estimate in the current model", 
      line = 0, adj = 0.7)
```

### Estimate SEM model 2

```{r}
#regression path estimates
sem.parameter <- parameterEstimates(sem2, standardized=TRUE) |>  # obtain estimates
  filter(op == "~") |>   #select "is measured by" rows
  select('DV*'=lhs, #left hand side column
         'IV*'=rhs, #right hand side column
         'B†'=est, #estimates
         'Beta‡'=std.all,#estimates standardized
         SE=se, #standard error
         Z=z, #z statistics
         'p-value'=pvalue #p value
         )

#round the p-value column
sem.parameter$`p-value` <- sem.parameter$`p-value` |> 
  round(3)

#add a conditional logic to the p-value column that >0.05 cell shows in red
sem.parameter$`p-value` <- cell_spec(sem.parameter$`p-value`, 
                                     color = ifelse(
                                       sem.parameter$`p-value` > 0.05, 
                                       "red", 
                                       "black")
                                     )
#furhter aesthetics 
sem.parameter |> 
  kable(digits = 3, #rounded to 3
        #format="latex", #Latex markdown
        booktabs=TRUE, #Latex booktabs
        linesep = "",
        caption= "Structural regression path and residual variance estimates.",
        escape = F) %>% #caption
  kable_styling(latex_options = "striped") %>% #gray every other row
  footnote(general = "Rows in bold have insignificant parameters.",
           symbol = c("DV: dependent variable; IV: independent variable",
                      "Crude estimates",
                      "Standardized estimates"))
```


```{r}
#Variance
type <- "Total variance" #create a new row clarifying types of variance

variance <- parameterEstimates(sem2, standardized=TRUE)  |>  #obtain estimates
  filter(op == "~~") #select "is correlated with" rows
variance <- variance[minus(sum(32,12), 5):sum(32,12),] #subset needed rows (variance row)
variance <- cbind(type, variance) #add column
sem.tab.variance <- variance %>%select(Type = type, #select and rename variables
                   Factor=rhs, #right hand side column
                   'B*'=est, #estimates
                   'Beta†'=std.all, #standardized estimates
                   SE=se,#standard error
                   Z=z, #z statistics
                   'p-value'=pvalue #p value
                   )  
#remove the row names
rownames(sem.tab.variance) <- NULL

#round the p-value column
sem.tab.variance$`B*` <- sem.tab.variance$`B*` |> 
  round(3)

#add a conditional logic to the p-value column that >0.05 cell shows in red
sem.tab.variance$`B*` <- cell_spec(sem.tab.variance$`B*`, 
                                     color = ifelse(
                                       sem.tab.variance$`B*` < 0, 
                                       "red", 
                                       "black")
                                     )
#display the logics 
sem.tab.variance |> 
  kable(digits = 3, #rounded
        #format="markdown",  #Latex markdown
        booktabs=TRUE, #Latex booktabs
        caption=
          "Residual variance of the dependent variables for initial model",
        escape = F) |>  #caption
  kable_styling(latex_options = "striped") |>    # gray every other row
  footnote(general = 
             "Negative crude residual variance will be highlighted in red",
           symbol = c("Crude estimates",
                      "Standardized estimates"))
```

### Comment on the result (model 2)

The estimation of Model 2 yielded an overall MLM χ2(426) value of 1450.985 (scaling correction factor = 1.117); CFI and TLI values of 0.950 and 0.945, respectively; a RMSEA value of 0.041; and a SRMR value of 0.046 (Table 7). Although improvement in model fit for Model 2, compared with the originally hypothesized model, would appear to be somewhat minimal on the basis of the CFI, TLI, RMSEA, and SRMR values, the corrected chi-square difference test was found to be significant (MLM Δχ2[1] = 91.67), which finalized the decision (Table 7).

_*Notes from Byrne's book: "the thrust of these post-hoc analyses is to fine-tune our hypothesized structure such that it includes all viable and statistically significant structural paths, and, at the same time, eliminates all non-significant paths. Consequently, as long as the ∆χ2-difference test is statistically significant, and the newly added parameters are substantively meaningful, I consider the post-hoc analyses to be appropriate."*_

The anomaly of negative residual variance remained in the output for Model 2 (Table 9). The estimated structural regression paths for the three factors hypothesized to influence Factor 10 (Factors 2, 3, and 4) and F1 to influence Factor 12 remained statistically non-significant (Table 8).

### Model mis-specification (model 2)

```{r}
#extract needed variables
MI.model2 <- modindices(sem2, 
                  standardized = TRUE, 
                  sort. = TRUE, 
                  maximum.number = 25) |> 
  filter(op == "~") |> 
  filter(lhs %in%  #When these factors are predicted variables, it is related
           c("F8SELF",  # to the topic of this study
             "F9ELC", 
             "F10EE", 
             "F11DP", 
             "F12PA")) 

#adapt to publication style
MI.model2 <- MI.model2 |> 
  mutate(Parameter = paste(rhs, "→", lhs)) |> 
  select(Parameter, MI = mi, EPC = epc, "std EPC" = sepc.all) |> 
  filter(MI>10) |> 
  mutate("Logics" = c("Sensible but not meaningful for this study",
                      "Sensible and meaningful",
                      "Sensibe and meaningful, but MI is lower than F5→F12"))

MI.model2
#add footnote symbol to parameters
  for (i in 1:nrow(MI.model2)){
  symbol <- c("*", "†", "‡") 
  Parameter <- unlist(MI.model2$Parameter)
  MI.model2$Parameter[i] <-  paste0(Parameter[i], symbol[i])
  }

#Visualize the table
MI.model2 |> 
  kable(digits = 3,
        booktab = T,
        linesep = "",
        caption = "Select modification indices for initial model") |> 
  kable_styling(latex_options = "striped") |> 
  row_spec(2, color = "red") |> 
  footnote(general = 
             "Parameter highlighted in red is selected for modification",
    symbol = c("Higher accomplishment leads to increased self-esteem",
             "Invovlement of more decision making gives sense of accomplishment",
             "People with high esteem will less likely get emotionally exhausted"))
```

## Post hos analysis (Model 3)

### Compare SEM model 3 with preceding models

I defined model 2 as per the conclusion from last section: set the regression path leading from F4 to F11 (Poorer Classroom climate leads to worsening depersonalization) free to estimate (Fig 6). The model fit indice comparison between the current model (model2) and the initial model was tabulated in table . 

```{r}
model3 <- paste(model2, "\nF12PA ~ F5DEC")

# Estimate the model with the robust (MLM) estimator:
sem3 <- sem(model3, data = mbi, estimator = "MLM", mimic = "Mplus")

# Numerical summary of the model:
sem.summary.mlm.a(sem3, 12, 32, "mlm", "Model fit indices for model 2") |> 
  unlist()

```

```{r}
sem.measure3 <- fitMeasures(sem3,    #obtain specified measured.
                            c("chisq.scaled", 
                              "df.scaled", 
                              "pvalue.scaled", 
                              "cfi.scaled", 
                              "tli.scaled",
                              "rmsea.scaled",
                              "srmr_bentler",
                              "chisq.scaling.factor")) |> 
  t() |> 
  round(3)
#combine the 2 sets of indices 
sem.compare3 <- rbind(sem.measure1, sem.measure2, sem.measure3) |> data.frame()

sem.compare3.tab <- sem.compare3
sem.compare3.tab$"Δχ2" <- rep(NA, 3)
sem.compare3.tab$"Δχ2"[2] <- chi.diff(sem1, sem2)
sem.compare3.tab$"Δχ2"[3] <- chi.diff(sem2, sem3)

#turn named vector to data frame
sem.compare3.tab<- sem.compare3.tab %>% 
  select("χ2" = chisq.scaled, "DF"=df.scaled, 
         "p value"=pvalue.scaled, "Δχ2", "CFI"= cfi.scaled,
         "TLI"= tli.scaled, "RMSEA"= rmsea.scaled, 
         "SRMR"=srmr_bentler, "CSF"=chisq.scaling.factor) 

sem.compare3.tab[1,4] <- "--"
rownames(sem.compare3.tab) <- c("model1", "model2*", "Model3")  

sem.compare3.tab |> 
  kable(booktab =T,
        #format = "markdown",
        caption = "Comparison of new and preceding models",
        align = "r") |> 
  kable_styling() |> 
  footnote(symbol = "Model1 + parameter 'F4→F11' set free to estimate")
```

### Estimate SEM model 3

### Comment on the result (model 3)

### Model mis-specification






## Post hos analysis (Model 4)

### Compare SEM model 4 with preceding models

### Estimate SEM model 4

### Comment on the result (model 4)

### Model mis-specification







## Post hos analysis (Model 5)

### Compare SEM model 5 with preceding models

### Estimate SEM model 5

### Comment on the result (model 5)

### Model mis-specification






## Post hos analysis (Model 6)

### Compare SEM model 6 with preceding models

### Estimate SEM model 6

### Comment on the result (model 6)

### Model mis-specification




*Note:* Here, we will use the sem() function for the estimation, instead of the cfa() function, as we are now working with a full SEM (i.e., CFA + regression paths).



## Exercise 4.2

Proceed **step by step** following the guidelines given in the lecture material, i.e., implement the modifications **one at a time**, testing and studying each step. See (and report) how the fit improves and which parameters are suggested to be modified. Please be careful! There will (always) be a lot of suggestions... Do not list all the MIs (only a few of them are useful!), try to keep your report as concise as possible.

*Note:* A good way to proceed is to collect the necessary information (i.e., which parameter was modified and how, MI, EPC, chi-square, df, CFI, TLI, scaling correction factor, RMSEA, and SRMR) of each modelling step to a **table** (in a way or another). (Some examples in R code were given in Assignment 3, consult also the reports by other students, if you do not know how to proceed.) **Such tables makes it easy to see how the results of the modelling develop through each step.** 

The best practice is to build the tables step by step: In the first table you will have only one row, then two rows, then three rows etc., and in the final version of the table you will have all the steps collected together on *k* rows, representing the *k* steps of the modelling process.

### Calculating the MLM $\chi^2$ difference tests

Calculate the MLM $\chi^2$ difference tests between the consecutive models of the above steps, as advised in the lecture material (p.14-15). Do those calculations in detail at least once or twice so that you get the idea.

*Note:* The formulas are simpler than they are in Byrne's book (p.168-169), where both MLM and ML estimations are needed. For more information, see: https://statmodel.com/chidiff.shtml.

For the calculations, you may use R (of course!) or Excel, or some ready-made calculation forms found on the web, such as https://www.thestatisticalmind.com/calculators/SBChiSquareDifferenceTest.htm.

```{r}

# (copy and modify the R codes given earlier)

```

## Exercise 4.3

Draw the graph of the final model and present its fit indices and the essential, standardized parameter estimates. **Pay attention to the factor correlations.**

Compare the initial and final graphs and make sure that you understand the whole modelling process and the final conclusions.

```{r}

# (copy and modify the R codes given earlier)

```

