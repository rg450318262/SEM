---
title: "COS-D419 Factor Analysis and Structural Equation Models 2023, Assignment 6"
author: "Rong Guang"
output:
  bookdown::pdf_document2:
    latex_engine: lualatex
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F, cache = F, fig.align = 'center')
```

```{r, echo = F}
## Exercise 6.1

#Establish a well-fitting and parsimonious baseline model for the calibration group.

#Although lavaan does not care about the extra items in the model (as Mplus does, see slide #16), you should remove the unnecessary factors and the related items in order to have the same number of the degrees of freedom in the consequent models as in the material. The revised (restructured) model (slide #17) consists of only **9 factors and their relations**.

#Draw the graphs of the hypothesized, modified, and restructured baseline models.
```

# Read Me

The texts that reflect my understanding/questions/doubts have been highlighted in \textcolor{red}{red color}. The texts that describes important steps/results have been highlighted in \textcolor{blue}{blue color}.

# Preparation

## Read in the data set

```{r}
library(tidyverse);library(readr);library(here)
latest.name1 <- "ELEMIND1.CSV"#This week's file name
latest.name2 <- "ELEMIND2.CSV"#This week's file name
#read in the data
ele.cali <-  #elementary school
  read_csv(
    file.path(
      here(),'data',
      latest.name1 ),
      show_col_types = FALSE
    )
ele.vali <- #secondary school
  read_csv(
    file.path(
      here(), 'data',
      latest.name2),
      show_col_types = FALSE
    )
```

## Write functions

Codes of functions were hidden from the current report. Yet they are available in .rmd report.

### Print a table with concerned parameters

```{r, echo = F}
#write a function for minus calculation
minus <- function(x,y) {x - y}
#write a function to print a table with concerned parameters
concern.table <- function(sem, nofpath = 0, nofpredictor = 0, model){
options(scipen = 999)
#This is for structural path residual variance
##regression path estimates
sem.parameter <- parameterEstimates(sem, standardized=TRUE) |>  # obtain estimates
  filter(op == "~") |>   #select "is measured by" rows
  mutate(Parameter = paste0(rhs, "→", lhs)) |>
  select(Parameter,
         'B'=est, #estimates
         'Beta'=std.all,#estimates standardized
         SE=se, #standard error
         Z=z, #z statistics
         'p-value'=pvalue #p value
         )
nofpath <- nrow(sem.parameter)
##round the p-value column
sem.parameter$`p-value` <- sem.parameter$`p-value` |>
  round(3)
##add a conditional logic to the p-value column that >0.05 cell shows in red
sem.parameter$`p-value` <- cell_spec(sem.parameter$`p-value`,
                                     color = ifelse(
                                       sem.parameter$`p-value` > 0.05,
                                       "red",
                                       "black")
                                     )
#This is for the residual variance of dependence variable
##obtain estimates
variance <- parameterEstimates(sem, standardized=TRUE)  |>
  filter(op == "~~") #select "is correlated with" rows
##subset needed rows (variance row)
variance <- variance %>%
  filter(str_detect(rhs, "SELF$|ELC$|EE$|DP$|PA$"), lhs == rhs)

n.dep <- nrow(variance)

#variance[minus(sum(32,nofpath), 5-1):sum(32,nofpath),] #32 is the n of indicators;
                                             #12 is the number of factors;
                                             #5 is the new of row I plan to show
##select&rename columns
sem.tab.variance <- variance |> select(
                   Parameter=rhs, #right hand side column
                   'B'=est, #estimates
                   'Beta'=std.all, #standardized estimates
                   SE=se,#standard error
                   Z=z, #z statistics
                   'p-value'=pvalue #p value
                   )
##remove the row names
rownames(sem.tab.variance) <- NULL
##round the p-value column
sem.tab.variance$`B` <- sem.tab.variance$`B` |>
  round(3)
##add a conditional logic to the beta column that <0 cell shows in red
sem.tab.variance$`B` <- cell_spec(sem.tab.variance$`B`,
                                     color = ifelse(
                                       sem.tab.variance$`B` < 0,
                                       "red",
                                       "black")
                                     )


covariance <- parameterEstimates(sem, standardized=TRUE)  |>
  filter(op == "~~", lhs != rhs)

n.cov <- nrow(covariance)

sem.tab.covariance <- covariance |>
  mutate(Parameter = paste0(rhs, "←→", lhs)) |>
  select(
    Parameter,
    #right hand side column
    'B' = est,
    #estimates
    'Beta' = std.all,
    #standardized estimates
    SE = se,
    #standard error
    Z = z,
    #z statistics
    'p-value' = pvalue #p value
  )

##remove the row names
rownames(sem.tab.covariance) <- NULL
##round the std estimate column
sem.tab.covariance$`Beta` <- sem.tab.covariance$`Beta` |>
  round(3)
##add a conditional logic to the p-value column that >0.05 cell shows in red
sem.tab.covariance$`Beta` <- cell_spec(sem.tab.covariance$`Beta`,
                                     color = ifelse(
                                       sem.tab.covariance$`Beta` > 1,
                                       "red",
                                       "black")
                                     )

#bind the three tables
concern.table <- rbind(sem.parameter, sem.tab.variance, sem.tab.covariance)

#round second column B un-standardized, rows of regression paths
concern.table[1:nofpath, 2] <-
  as.character(round(as.numeric(concern.table[1:nofpath, 2]),3))
#round second column B un-standardized, rows of residual covariance
concern.table[sum(nofpath, n.dep, 1):sum(nofpath, n.cov,n.dep), 2] <-
  as.character(round(as.numeric(concern.table[sum(nofpath, n.dep, 1):sum(nofpath, n.cov,n.dep), 2]),3))

#round last column p value, all rows
concern.table[sum(nofpath,1):sum(nofpath, n.cov, n.dep),6] <-
  as.character(round(
    as.numeric(
      concern.table[sum(nofpath,1):sum(nofpath, n.cov, n.dep),6]
      ),
    3)
    )
#round third column standardized B, all rows
concern.table[1:sum(nofpath, 5),3] <-
  as.character(round(
    as.numeric(
      concern.table[1:sum(nofpath, 5),3]
      ),
    3)
    )

#further aesthetics
concern.table |>
  select("Parameter*" = Parameter,
         'B†' = B, #estimates
         'Beta‡' = Beta,#estimates standardized
         SE, #standard error
         Z, #z statistics
         'p-value') |> #p value
  kable(digits = 3, #rounded to 3
        #format="latex", #Latex markdown
        booktabs=TRUE, #Latex booktabs
        linesep = "",
        align = "lrrrrr",
        caption=
          paste(
            "Residual variance of structural regression path and select factors for",
            model),
        escape = F) |> #caption
  kable_styling(latex_options = "striped") |> #gray every other row
  pack_rows("Regression paths (Residual variance)",
            1,nofpath) |>
  pack_rows("Endogenous factors(Residual variance)",
            sum(nofpath,1), sum(nofpath,5)) |>
  pack_rows("Exogenous factors (Residual covariance)",
            sum(nofpath, 6), sum(nofpath, 5, n.cov)) |>
  footnote(general = "Values highlighted in red should be taken note of",
           symbol = c("→ indicates regression path; ←→ indicates covariance",
                      "Crude estimates",
                      "Standardized estimates"))
}
```

### SEM results with improved readability

```{r, echo = F}
#goodness of fit indicators for ml
cfa.summary.mlm.a <- function(fit){
  options(scipen = 999)
  cfa.measure <- fitMeasures(fit,    #obtain specified measured.
                            c("chisq.scaled", 
                              "df.scaled", 
                              "pvalue.scaled", 
                              "cfi.scaled", 
                              "tli.scaled",
                              "rmsea.scaled",
                              "rmsea.pvalue.scaled",
                              "srmr_bentler",
                              "chisq.scaling.factor")) 
  names(cfa.measure) <- c("chi square", "df", "p value", "CFI", "TLI", "RMSEA", "RMSEA p value", "SRMR", "CSF")
  #turn named vector to data frame
cfa.tab.a <- cfa.measure %>%  
  tibble(name= names(cfa.measure), value = cfa.measure) %>% # vector to df
  select(Measure = name, Value = value) %>%  #select and rename columns
  mutate(Value = round(as.numeric(Value),3)) 
}
#factor loading
cfa.summary.b <- function(fit, fa.num, item.num, estimator){
  options(scipen = 999)
  #factor loading
  cfa.tab.b <- parameterEstimates(fit, standardized=TRUE) %>% # obtain estimates
  filter(op == "=~") %>%  #select "is measured by" rows
  mutate(Parameter = paste0(lhs, "→", rhs),
         pvalue = case_when(as.numeric(pvalue)<0.001~"<0.001", 
                            as.numeric(pvalue)>=0.001~as.character(pvalue)
                            )
         ) |> 
  select(Parameter,
         Beta=std.all, #std estimates
         SE=se, #standard error
         Z=z, #z statistics
         'p-value'=pvalue #p value
         ) 
  # %>%  
  # kable(digits = 3, #rounded to 3
  #       format="markdown", #Latex markdown
  #       booktabs=TRUE, #Latex booktabs
  #       caption=paste("Factor Loadings for",fa.num,"factor CFA model estimated by ", estimator)) %>% #caption
  # kable_styling(latex_options = "striped") %>% #gray every other row
  # row_spec(0, background = "#9999CC") # color the first row
  # cfa.tab.b
  }

#Variance
cfa.summary.c <- function(fit, fa.num, item.num, estimator){
  options(scipen = 999)
  #Variance
  type <- rep(c("Residual", "Total"), 
            time = c(item.num, fa.num)) #create a new row clarifying types of variance

variance <- parameterEstimates(fit, standardized=TRUE) %>% #obtain estimates
  filter(op == "~~") #select "is correlated with" rows
variance <- variance[1:sum(item.num,fa.num),] #subset 1:18 rows (variance row)
variance <- cbind(type, variance) #add column
cfa.tab.c <- variance |> 
  mutate(pvalue = case_when(as.numeric(pvalue)<0.001~"<0.001", 
                            as.numeric(pvalue)>=0.001~as.character(pvalue)
                            )) |> 
  select(Parameter = type, #select and rename variables
                   Indicator=rhs, #right hand side column
                   B=est, #estimates
                   "Beta*"=std.all,#std estimates
                   SE=se,#standard error
                   Z=z, #z statistics
                   'p-value'=pvalue #p value
                   ) 

# %>% 
#   kable(digits = 3, #rounded
#         format="markdown",  #Latex markdown
#         booktabs=TRUE, #Latex booktabs
#         caption=paste("Variances for", fa.num, "factor model estimated by ", estimator)) %>% #caption
#   kable_styling(latex_options = "striped") %>% # gray every other row
#   row_spec(0, background = "#9999CC") # color the variable row
#   cfa.tab.c
}

#Covariance
cfa.summary.d <- function(fit, fa.num, item.num, estimator){
  options(scipen = 999)
  #covariance
  variance <- parameterEstimates(fit, standardized=TRUE) %>%
  filter(op == "~~")
  covar.num = (fa.num+(fa.num-1))/2
variance <- variance[sum(item.num,fa.num,1):sum(item.num,fa.num,covar.num),]
type <- paste(variance$lhs, "←→", variance$rhs) 
variance <- cbind(type, variance)
rownames(variance) <- NULL
cfa.tab.d <- variance |> 
  mutate(pvalue = case_when(as.numeric(pvalue)<0.001~"<0.001", 
                            as.numeric(pvalue)>=0.001~as.character(pvalue)
                            )) |> 
  select(Parameter=type,
         B=est, 
         Beta=std.all,
         SE=se,
         Z=z, 
         'p-value'=pvalue 
         )
# %>% 
#   kable(digits = 3, 
#         format="markdown", 
#         booktabs=TRUE, 
#         caption=paste("Covariances for", fa.num, 
#                       "factor model estimated by ", 
#                       estimator)) %>% 
#   kable_styling(latex_options = "striped") %>% 
#   row_spec(0, background = "#9999CC")
#   cfa.tab.d
}

```

### Simplify plotting of merged tables for multi-group fit indicies

```{r, echo=F}
multi.fit.tab <- function(data, title, more.footnote = NULL){
  
  if (nrow(data)>=4){
    option <- "'striped'"
  } else {
    option <- "NULL"
  }
  
data <- data |> 
  rename(p = 'p value',
         p2 = 'RMSEA p value',
         chi = 'chi square') |> 
  mutate(df = as.numeric(df) |> round(0),
         p = case_when(
           as.numeric(p) < 0.001 ~ "<0.001",
           as.numeric(p) >= 0.001 ~ p
           ),
         p2 = case_when(
           as.numeric(p2) < 0.001 ~ "<0.001",
           as.numeric(p2) >= 0.001 ~ p2
           )
         ) |>
  mutate('Chi square (df, p)' = 
           paste0(chi, "(", df,", ", p, ")"),
         'RMSEA(p)'           = 
           paste0(RMSEA, "(", p2, ")"
                  )
         ) |> 
  select(
    Model,
    'Chi square (df, p)', 
    CFI, TLI,
    'RMSEA(p)', 
    SRMR, 
    'CSF*'= CSF
    ) 
#print the combined table with adjustment of aesthetics
data |> 
  kable(booktabs = T, 
        #format = "markdown", 
        caption = 
          title,
        align = "lrrrrrr",
        linesep =""
        ) |> 
  kable_styling(#full_width = T,
                #latex_options = "striped"
                latex_options =  eval(parse(text = option))
                ) |> 
  footnote(symbol = 
             c("Chi square scaling factor", 
               more.footnote)
           ) |>
  column_spec(1, width = "3.2cm") |> 
  column_spec(2, width = "4cm")|> 
  column_spec(3, width = "1cm")|> 
  column_spec(4, width = "1cm")|> 
  column_spec(5, width = "2.3cm")|> 
  column_spec(6, width = "1cm") |> 
  column_spec(7, width = "1cm") 
}

```

```{r, echo=F}
multi.fit.tab2 <- function(data, title, more.footnote = NULL){
  
  if (nrow(data)>=4){
    option <- "'striped'"
  } else {
    option <- "NULL"
  }
  
data <- data |> 
  rename(p = 'p value',
         p2 = 'RMSEA p value',
         chi = 'chi square') |> 
  mutate(df = as.numeric(df) |> round(0),
         p = case_when(
           as.numeric(p) < 0.001 ~ "<0.001",
           as.numeric(p) >= 0.001 ~ p
           ),
         p2 = case_when(
           as.numeric(p2) < 0.001 ~ "<0.001",
           as.numeric(p2) >= 0.001 ~ p2
           )
         ) |>
  mutate('Chi square (df, p)' = 
           paste0(chi, "(", df,", ", p, ")"),
         'RMSEA(p)'           = 
           paste0(RMSEA, "(", p2, ")"
                  )
         ) |> 
  select(
    Model,
    'Chi square (df, p)',
    "ΔChi-square(df,p)*" = diff,
    CFI, TLI,
    RMSEA, 
    SRMR
    ) 
#print the combined table with adjustment of aesthetics
data |> 
  kable(booktabs = T, 
        #format = "markdown", 
        caption = 
          title,
        align = "lrrrrrr",
        linesep =""
        ) |> 
  kable_styling(#full_width = T,
                #latex_options = "striped"
                latex_options =  eval(parse(text = option))
                ) |> 
  footnote(symbol = 
             c("ΔChi-square by ANOVA() function, comparing with the preceding model", 
               more.footnote)
           ) |>
  column_spec(1, width = "3.2cm") |> 
  column_spec(2, width = "3.4cm")|> 
  column_spec(3, width = "3.2cm")|> 
  column_spec(4, width = "0.8cm")|> 
  column_spec(5, width = "0.8cm")|> 
  column_spec(6, width = "1.3cm") |> 
  column_spec(7, width = "1cm") 
}

```

### Histogram overlapping with density plot

```{r, echo = F}
corr.density <- function(data, fig.num = 1, group){
  data %>%
  pivot_longer(everything()) %>%  #longer format
  ggplot(aes(x = value)) + #x axis used variable "value" (a default of pivot)
  geom_histogram(binwidth = 1, aes(y = ..density..), #match ys of density and histogram plots
                 color = "black",  fill = "#9999CC")+  # adjust aesthetics for hist
  geom_density(fill = "pink", alpha = 0.25)+ #adjust aesthetics for density plot
  facet_wrap(~name, scales = "free", ncol =5) + #wrap by name variable
  theme(panel.grid.major = element_blank(), #get rid of the  grids
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white",#adjust the background
                                        color = "black"),
        strip.background = element_rect(color = "black",#adjust the strips aes
                                        fill = "steelblue"),
        strip.text = element_text(size =8, color = "white"), #adjust strip text
        axis.title.x = element_text(size = 3), #adjust the x text
        axis.title.y = element_text(size = 3), # adjust the y text
        plot.title = element_text(size = 12,
                                  face = "bold",
                                  hjust = 0.5))+ #adjust the title
  labs(title = paste("Figure", fig.num," Distribution of the indicators for", group)) #title it
  }
```

### Dot distribution plot

```{r, echo=F}
dot.dist <- 
  function(data, type, title){
    data |>
      t() |> 
      as.data.frame() %>% 
      mutate(Item = rownames(.)) |> 
      rowwise() |> 
      mutate(Median = eval(parse(text = type))(V1:V580)) |> 
      ggstatsplot::ggdotplotstats(
        point.args = list(color = "red", size = 3, shape = 13),
        xlab = paste(type, "ratings"),
        title = title,
        x = Median,
        y = Item
      )
    }
```

### Correlation matrix with statistical test

```{r, echo=F}
mycor <- 
  function(data, cols, title){
  data |> 
      select(all_of(cols)) |> 
      ggstatsplot::ggcorrmat(
        colors = c("#B2182B", "white", "#4D4D4D"),
        title = title,
        matrix.type  = "lower"
      )
    }
```

# Inspect the data

## Distribution of values

```{r,fig.width= 8, fig.height = 13}
p.dist.elm <- #generate the plots, by subgroup of teachers
  corr.density(
    ele.cali,  fig.num = "1(a)", 
    group = "calibration dataset"
    )
p.dist.sec <- 
  corr.density(
    ele.vali, fig.num = "1(b)",
    group = "validation dataset"
    )
library(patchwork); p.dist.elm/p.dist.sec#print the plot
```

## Distributions of Item statistics (median)

```{r,fig.width= 8, fig.height = 6}
#generate plot by subgroups of teachers
p.dot.elm <- 
  dot.dist(data = ele.cali, type = "median", 
    title = "(a) Calibration dataset" )
p.dot.sec <- 
  dot.dist( data = ele.vali,  type = "median", 
    title = "(b) Validation dataset")
#plot layout
patchwork <- p.dot.elm|p.dot.sec
#print the plot with a general title
patchwork+plot_annotation(
    title = 'Figure 2 Distributions of median rating for each item',
    theme =  theme(plot.title = element_text(
                size = 16, face = "bold",
                vjust = -1.5,hjust =0.5)))
```

## Correlation

```{r,fig.width= 10, fig.height = 15}
#save variable names of MBI indicators to object
indi.EE <- 
  paste0("EE", 1:3)
indi.DP <- 
  paste0("DP", 1:2)
indi.PA <- 
  paste0("PA", 1:3)
scale.MBI <-  
  c(indi.EE, 
    indi.DP,  
    indi.PA)
#save var names of TSS indicators to object
indi.ROLEC <- 
  paste0("ROLEC", 1:2)
indi.ROLEA <- 
  paste0("ROLEA", 1:2)
indi.WORK <- 
  paste0("WORK", 1:2)
indi.CLC <- 
  paste0("CCLIM", 1:4)
indi.DEC <- 
  paste0("DEC", 1:2)
indi.SUPS <- 
  paste0("SSUP", 1:2)
indi.PEERS <- 
  paste0("PSUP", 1:2)

scale.TSS <- 
  c(
    indi.ROLEC, 
    indi.ROLEA, 
    indi.WORK, 
    indi.CLC, 
    indi.DEC, 
    indi.SUPS, 
    indi.PEERS
    )
#generate the correlation plots scale-wise
scale.SE <- paste0("SELF", 1:3);scale.ELC <- paste0("ELC", 1:5)
p.cor.MBI.cali <- 
       mycor( data = ele.cali,  
              cols = scale.MBI, 
         "(a1) Indicators on MBI, 
         calibration dataset"
         )
p.cor.MBI.vali <- 
       mycor( data = ele.vali,  
              cols = scale.MBI, 
         "(a2) Indicators on MBI, 
         validation dataset" 
         )
p.cor.TSS.cali <- 
       mycor( data = ele.cali, 
              cols = scale.TSS, 
         "(b1) Indicators on TSS, calibration dataset"
         )
p.cor.TSS.vali <- 
       mycor(data = ele.vali,  
             cols = scale.TSS, 
         "(b2) Indicators on TSS, validation dataset"
         )
p.cor.SE.cali <- 
       mycor(data = ele.cali,  
             cols = scale.SE, 
         "(c1) Indicators on self-esteem, 
         calibration dataset"
         )
p.cor.SE.vali <- 
       mycor( data = ele.vali,  
              cols = scale.SE, 
         "(c2) Indicators on self-esteem, 
         validation dataset"
         )
p.cor.ELC.cali <- 
       mycor( data = ele.cali,  
              cols = scale.ELC, 
         "(d1) Indicators on external locus of control, 
         calibration dataset"
         )
p.cor.ELC.vali <- 
       mycor( data = ele.vali, 
              cols = scale.ELC, 
         "(d2) Indicators on external locus of control, 
         validation dataset" 
         )
patchwork1 <- #plot sub-figure layout
  p.cor.MBI.cali/p.cor.SE.cali/p.cor.ELC.cali|
  p.cor.MBI.vali/p.cor.SE.vali/p.cor.ELC.vali
patchwork2 <- 
  p.cor.TSS.cali/p.cor.TSS.vali
patchwork1+
  plot_annotation(
  title = 'Figure 3-1 Correlalogram for TSS indicators',
    theme =  theme(plot.title = 
              element_text(
                size = 16, 
                face = "bold", 
                vjust = -1.5, 
                hjust =0.5 
                )
              )
    )
```

The correlation plots showed the following findings relevant to the current study.

a. Within each separate single-factor scale, the correlation among indicators are fairly high. See figure 3 (c) and (d), with most exceeding a value of 0.4, and all exceeding 0.3.

b. Not much differences in correlation coefficients were observed across calibration and validation data sets. For example, across MBI samples (figure 3-1(a)), no value discrepancy was higher than 0.12, with most difference observed in the second decimal place. This finding corresponds to the conclusion of multi-sample in-variance from the following analysis.

d. Within each multi-facets scale (MBI and TSS), the correlation can be low among some indicators. However, if only looking at the indicators within each factor, the correlation are fairly high, with most exceeding 0.5 for MBI (Figure 3-1 (a)), and most exceeding 0.4 for TSS.

e. Most of the correlation coefficients between indicators of WORK and ROLEC were higher than 0.5, being the highest between-indicator values within TSS scale, for both validation and calibration data-sets. See figure 3-2 This provides further evidence for the combination of the two indicators in the following model re-specification.

f. Some correlation coefficients of CLIM indicators within TSS scale were very weak, yielding non-significant correlation among validation data set. Though also very low, the corresponding values in calibration data-set were statistically significant. Special attention should be paid for the equivalence of coefficient estimates across samples for configural model. See figure 3-2.

```{r,fig.width= 10, fig.height = 15}
patchwork2+
  plot_annotation(
    title = 'Figure 3-2 Correlalogram for indicators of MBI, self-esteem, external 
    locus of control scales',
    theme = 
      theme(
        plot.title = 
          element_text(
            size = 16, 
            face = "bold", 
            vjust = -1.5, 
            hjust =0.5 
            )
        )
    )
```

# Test the equivalence of causal structure across calibration and validation samples

This involves three steps:

(a) Define, modify and estimate a baseline model for the calibration group:

(b) Form and test the multi-group configural model with no parameter constraints.

(c) test for the in-variance of common structural regression (or causal) paths across calibration and validation groups. 

## Define and estimate the baseline model for the calibration group

### Establish and modify the hypothesized model (initial model) for calibration group 

(1) Define the initial model for calibration group

```{r}
initial.model <- '
# Burnout Factors:
# EE: EmotionalExhaustion;DP: Depersonalization;PA: PersonalAccomplishment
 F1ROLA =~ ROLEA1 + ROLEA2
 F2ROLC =~ ROLEC1 + ROLEC2
 F3WORK =~ WORK1 + WORK2
 F4CLIM =~ CCLIM1 + CCLIM2 + CCLIM3 + CCLIM4
 F5DEC =~ DEC1 + DEC2
 F6SSUP =~ SSUP1 + SSUP2
 F7PSUP =~ PSUP1 + PSUP2
 F8SELF =~ SELF1 + SELF2 + SELF3
 F9ELC =~ ELC1 + ELC2 + ELC3 + ELC4 + ELC5
 F10EE =~ EE1 + EE2 + EE3
 F11DP =~ DP1 + DP2
 F12PA =~ PA1 + PA2 + PA3
# Regression paths:
 F8SELF ~ F5DEC + F6SSUP + F7PSUP
 F9ELC ~ F5DEC
 F10EE ~ F2ROLC + F3WORK + F4CLIM
 F11DP ~ F2ROLC + F10EE
 F12PA ~ F1ROLA + F8SELF + F9ELC + F10EE + F11DP
'
```

(2) Visualize the initial model for calibration group

To approximate the visual effect on slides, the coordinates for each nodes were defined on a 60 by 72 matrix.

```{r}
library(semPlot)
#generate a matrix
m <- matrix(NA, 60, 72)
#define positions of the factors
m[12, 68] <- "F1ROLA"
m[12, 40] <- "F2ROLC"
m[12, 28] <- "F3WORK"
m[12,12] <- "F4CLIM"
m[21,12] <-"F5DEC"
m[40,12] <-"F6SSUP"
m[53,9] <-"F7PSUP"
m[44,24] <-"F8SELF"
m[52,40] <-"F9ELC"
m[37,48] <-"F10EE"
m[26,60] <-"F11DP"
m[48,64] <-"F12PA"
#define the positions of the indicators (parcelled items)
m[4, 72] <- "ROLEA1"
m[4, 64] <- "ROLEA2"
m[4, 48] <- "ROLEC1"
m[4, 40] <- "ROLEC2"
m[4, 32] <- "WORK1"
m[4, 24] <- "WORK2"
m[4, 16] <- "CCLIM1"
m[5, 10] <- "CCLIM2"
m[10, 4] <- "CCLIM3"
m[15, 4] <- "CCLIM4"
m[20, 4] <- "DEC1"
m[27, 6] <- "DEC2"
m[36, 4] <- "SSUP1"
m[40, 4] <- "SSUP2"
m[59, 6] <- "PSUP1"
m[59, 13] <- "PSUP2"
m[48, 32] <- "SELF1"
m[52, 28] <- "SELF2"
m[51, 21] <- "SELF3"
m[56, 50] <- "ELC1"
m[60, 48] <- "ELC2"
m[60, 42] <- "ELC3"
m[60, 35] <- "ELC4"
m[56, 31] <- "ELC5"
m[43, 45] <- "EE1"
m[39, 40] <- "EE2"
m[35, 38] <- "EE3"
m[20, 64] <- "DP1"
m[20, 58] <- "DP2"
m[52, 71] <- "PA1"
m[56, 64] <- "PA2"
m[53, 57] <- "PA3"
```

The diagram of the initial model was generated.

```{r, fig.height =  10, fig.width = 14, cache=TRUE}
semPaths(semPlotModel(initial.model),
         style = "lisrel",
         rotation = 2,
         sizeLat = 6,
         sizeLat2 = 5,
         sizeMan = 5,
         sizeMan2 = 2,
         residScale = 4,
         shapeMan = "rectangle",
         edge.color = c(rep("black", 32), #34 
                        rep("blue", 14),
                        rep("gray", 32),
                        rep("red", 5)), 
         residuals = T,  
         layout = m,
         nCharNodes=0,
         optimizeLatRes = T,
         exoVar = F)
title(main = list("Figure 4. Hypothesized model of elementary teacher burnout",
                  cex = 1.5, font =1),
     outer = F, line = -1)
title(
  sub = 
  "Notes: Red arrow indicates factor residuals; gray arrow indicates error residuals;
  blue arrow indicates regression path; black arrow indicates factor loading",
  ine = 0, adj = 0.7
  )
```

(3) Estimate the initial model for calibration group

```{r}
library(lavaan)
library(knitr)
library(kableExtra)
model1 <- initial.model # defined above
# Estimate the model with the robust (MLM) estimator:
sem1 <- 
  sem(
    model1,
    data = ele.cali,
    estimator = "MLM",
    mimic = "Mplus"
  )
# Numerical summary of the model:
sem1.fit <-
  cfa.summary.mlm.a(sem1) |>
  t() |>
  as.data.frame() 

names(sem1.fit) <- sem1.fit[1,]
sem1.fit <- sem1.fit[-1,]
rownames(sem1.fit) <- NULL

sem1.fit <- 
  sem1.fit |> 
  mutate(Model = "Initial model") |> 
  select(Model, everything())
#print the table
multi.fit.tab(sem1.fit, "Fit indices for calibration dataset(initial model)")
```

\textcolor{blue}{The values of fit indices were basically acceptable, though most of them had not yet reached required cutoff}. See table 1. However, residual variance and co-variance still needed to be checked for any anomaly. 

```{r}
#print concern table for model 1
concern.table(sem1, 
              nofpath = 14, 
              nofpredictor = 7, 
              "model1")
```

See table 2. I can readily see a couple of structural regression paths were not significant. I left these aberrant parameters untreated for the current stage.

\textcolor{blue}{The correlation between Factors 3 (workload) and 2 (role conflict) exceeds a value of 1.00, which are Heywood cases.} This finding indicated a definite overlapping of variance between the factors of Role Conflict and Work Overload such that divergent (i.e., discriminant) validity between these two constructs is in-distinctive. It needed to be addressed.

(4) Re-specification of initial model to model 2

\textcolor{blue}{Given the two factors in the Heywood case are different factors comprising TSS construct, one approach is to combine these two factors into one, leading to 12-1=11 factors in the structure. I did this and refit the model (model 2). }

```{r}
#replace the old parameters with new one
library(stringr)
model2 <- 
  initial.model |> 
  str_replace(".F3WORK.=~.WORK1.+.WORK2\n", "") |> 
  str_replace(".F2ROLC.=~.ROLEC1.+.ROLEC2", 
              " F2ROWO =~ ROLEC1 + ROLEC2 + WORK1 + WORK2") |> 
  str_replace_all("F3WORK", "F2ROWO") |> 
  str_replace_all("F2ROLC", "F2ROWO") |> 
  str_replace_all("F2ROWO.+.F2ROWO", "F2ROWO")

#update the factor indexing
for (i in 4:12){
  original <- paste0("\\sF", i) # \\s is  regex for white-space
  new <- paste0(" F", i-1)
  model2 <- model2 |> 
    str_replace_all(original, new)
}
```

### Establish and modify the model 2 for calibration group 

(1) Visualize model 2

```{r}
m[12, 40] <- NA
m[12, 28] <- NA
m[12, 35] <- "F2ROWO"
m[12,12] <- "F3CLIM"
m[21,12] <-"F4DEC"
m[40,12] <-"F5SSUP"
m[53,9] <-"F6PSUP"
m[44,24] <-"F7SELF"
m[52,40] <-"F8ELC"
m[37,48] <-"F9EE"
m[26,60] <-"F10DP"
m[48,64] <-"F11PA"
m[4, 24] <- NA
m[4, 48] <- NA
m[7, 26] <- "WORK2"
m[7, 46] <- "ROLEC1"
```

```{r, fig.height =  10, fig.width = 14, cache=TRUE}
grps <- list(
  c("F2ROWO"),
  c(
    "F3CLIM",
    "F4DEC",
    "F5SSUP",
    "F6PSUP",
    "F7SELF",
    "F8ELC",
    "F9EE",
    "F10DP",
    "F11PA",
    "F1ROLA"
  ))
semPaths(semPlotModel(model2),
         style = "lisrel",
         rotation = 2,
         sizeLat = 6,
         sizeLat2 = 5,
         sizeMan = 5,
         sizeMan2 = 2,
         residScale = 4,
         shapeMan = "rectangle",
         edge.color = c(rep("black", 32), #34 
                        rep("blue", 13),
                        rep("gray", 32),
                        rep("red", 5)), 
         residuals = T,
         layout = m,
         nCharNodes=0,
         optimizeLatRes = T,
         exoVar = F,
         group = grps,
         color = c("orange", "white"))
title(main = list("Figure 5. Model 2 of teacher burnout, modified from initial model",
                  cex = 1.5, font =1),
     outer = F, line = -1)
title(sub = 
"Notes: Red arrow indicates factor residuals; gray arrow indicates error residuals;
        Blue arrow indicates regression path; black arrow indicates factor loading;
                                         Newly merged factor is highlighted in orange",
     line = 0, adj = 0.7)
```

(2) Estimate model2 for calibration group

```{r}
sem2 <- 
  sem(
    model2,
    data = ele.cali,
    estimator = "MLM",
    mimic = "Mplus"
  )
```

For the convienience of calculating chi-square difference with anova

```{r}
chi.diff.anova <- function(sem1, sem2) {
  chi <- anova(sem2, sem1)$'Chisq diff'[2] |> round(3)
  df <- anova(sem2, sem1)$Df[2] - anova(sem2, sem1)$Df[1]
  p <- anova(sem2, sem1)$'Pr(>Chisq)'[2] |> round(3)
  p <- ifelse(as.numeric(p) < 0.001, "<0.001", as.character(p))
  value <- paste0(chi, "(", df, ",", p, ")"); return(value)
}
```


```{r}
# Numerical summary of the model:
sem2.fit <-
  cfa.summary.mlm.a(sem2) |>
  t() |>
  as.data.frame() 
#extracted and calculate needed values
names(sem2.fit) <- sem2.fit[1,]
sem2.fit <- sem2.fit[-1,]
rownames(sem2.fit) <- NULL
sem2.fit <- 
  sem2.fit |> 
  mutate(Model = "Model2†") |> 
  select(Model, everything())
#combine with preceding fit indices
sem12.fit <- rbind(sem1.fit, sem2.fit)
#add chi square difference value
sem12.fit$diff <- c("--", chi.diff.anova(sem1, sem2))
#print the table
multi.fit.tab2(sem12.fit, 
              "Fit indices for calibration dataset, model2 comparing with preceding model",
              "Initial model with Factors 3 (workload) and 2 (role conflict) combined")
```

See table 3. Goodness-of-fit statistics for this modified model 2 were as follows: chi-square(436) = 955.863, CFI= 0.943, RMSEA = 0.045, suggesting relatively well fit. 

(3) Re-specification of model 2 to model 3&4

```{r}
#extract needed variables
MI.model2 <- modindices(sem2,
                  standardized = TRUE,
                  sort. = TRUE,
                  maximum.number = 50) |>
  filter(op %in% c("~","~~")) 
#adapt to publication style
MI.model2 <- MI.model2 |>
  mutate(op = ifelse(op == "~", "→","←→"),
    Parameter = paste(rhs, op, lhs)) |>
  select(
    'Parameter*' = Parameter,
    MI = mi,
    EPC = epc,
    "std EPC" = sepc.all
  ) |>
  filter(MI > 30) 
#print the table
MI.model2 |> 
  kable(digits = 3,
        booktab = T,
        linesep = "",
        caption = "Selected modification indices for model 2") |>
  kable_styling(latex_options = "striped") |>
  row_spec(c(1,2), color = "red") |>
  footnote(general =
             "Parameters highlighted in red is of special concern",
    symbol = c('"→" indicates regression path; "←→" indicates residual covariance'))
```

See table 4. \textcolor{blue}{Two parameters with the highest values were substantively meaningful.} They are (a) the structural path of F8 on F2 (External Locus of Control on Role Conflict/Work Overload) and (b) a covariance between residuals associated with the observed variables EE1 and EE2, \textcolor{blue}{both of which are highlighted in red}. \textcolor{blue}{They were incorporated into the model consecutively}. F8 on F2 went first. They were re-specified as follows:

```{r}
model3 <- paste(model2, "F8ELC ~ F2ROWO\n")
model4 <- paste(model3, "EE1 ~~ EE2\n")
```

### Establish and modify the model 3 and model 4 for calibration group, consecutively

(1) Visualize model 2 and model 3

\textcolor{blue}{Model 3 was defined by re-specifying model. After model 3 was estimated, model 4 was defined by re-specifying model 3.}

```{r, fig.height =  16, fig.width = 11, cache=TRUE}
par(mfrow=c(2,1))#set plot layout
#draw model 3 diagram
semPaths(semPlotModel(model3),
         style = "lisrel",
         rotation = 2,
         sizeLat = 6,
         sizeLat2 = 5,
         sizeMan = 5,
         sizeMan2 = 2,
         residScale = 4,
         shapeMan = "rectangle",
         edge.color = c(rep("black", 32), #34 
                        rep("blue", 13),
                        rep("orange",1),
                        rep("gray", 32),
                        rep("red", 5)), 
         residuals = T,
         layout = m,
         nCharNodes=0,
         optimizeLatRes = T,
         exoVar = F)
title(main = list(
  "Figure 6. Model 3 of elementary teacher burnout, modified from model 2",
                  cex = 1.5, font =1
  ),outer = F, line = -1)
title(sub = "Notes: Red arrow indicates factor residuals; gray arrow indicates error residuals;
     Blue arrow indicates regression path; black arrow indicates factor loading;
     Newly incorporated parameter is highlighted in orange",
     line = 1, adj = 0.7)
#fine-tune the positions of EE1 and EE2, to make their covariance manifest
m[43, 45] <- NA
m[39, 40] <- NA
m[43, 52] <- "EE1"
m[42, 42] <- "EE2"
#draw model 4 diagram
semPaths(semPlotModel(model4),
         style = "lisrel",
         rotation = 2,
         covAtResiduals = F,
         sizeLat = 6,
         sizeLat2 = 5,
         sizeMan = 5,
         sizeMan2 = 2,
         residScale = 4,
         shapeMan = "rectangle",
         edge.color = c(rep("black", 32), #34 
                        rep("blue", 14),
                        rep("orange",1),
                        rep("gray", 32),
                        rep("red", 5)), 
         residuals = T,
         layout = m,
         nCharNodes=0,
         optimizeLatRes = T,
         exoVar = F #if exogenous variables also has variance estimated
         )
title(main = list(
  "Figure 7. Model 4 of elementary teacher burnout, modified from model 3",
                  cex = 1.5, font =1
  ),outer = F, line = -1)
title(sub = "Notes: Red arrow indicates factor residuals; gray arrow indicates error residuals;
     blue arrow indicates regression path; black arrow indicates factor loading;
     Newly incorporated covariance is highlighted in orange",
     line = 1, adj = 0.7)
```

(3) Estimate model 3 and model 4 for calibration group

```{r}
sem3 <- 
  sem(
    model3,
    data = ele.cali,
    estimator = "MLM",
    mimic = "Mplus"
  )
sem4 <- 
  sem(
    model4,
    data = ele.cali,
    estimator = "MLM",
    mimic = "Mplus"
  )
```

```{r}
# Numerical summary of the model:
sem3.fit <-
  cfa.summary.mlm.a(sem3) |>
  t() |>
  as.data.frame() 
sem4.fit <-
  cfa.summary.mlm.a(sem4) |>
  t() |>
  as.data.frame()
#model3, extracted needed values
names(sem3.fit) <- sem3.fit[1,]
sem3.fit <- sem3.fit[-1,]
rownames(sem3.fit) <- NULL
sem3.fit <- 
  sem3.fit |> 
  mutate(Model = "Model3‡") |> 
  select(Model, everything())
#model4, extracted needed values
names(sem4.fit) <- sem4.fit[1,]
sem4.fit <- sem4.fit[-1,]
rownames(sem4.fit) <- NULL

sem4.fit <- 
  sem4.fit |> 
  mutate(Model = "Model4§") |> 
  select(Model, everything())
#add chi-square difference value
sem3.fit$diff <- chi.diff.anova(sem2, sem3)
sem4.fit$diff <- chi.diff.anova(sem3, sem4)
#combine with preceding fit indices
sem1234.fit <- rbind(sem12.fit, sem3.fit, sem4.fit)
#print the table
multi.fit.tab2(sem1234.fit, 
              "Fit indices for calibration dataset, model 3 and model 4 
               comparing with preceding models",
              c("Model2: Initial model with Factors 3 and 2 combined",
                "Model3: Model2 with parameter F8 on F2 freely estimated",
                "Model4: Model3 with residual covariance between EE1 and EE2 estimated"))
```

See table 5. Model had a chi-square[435] of 907.120, CFI of 0.948 and SRMR of 0.05; Fit of model 4 further improved in comparison to model 3, yielding a chi-square[434] of 866.557 with CFI of 0.953 and SRMR of 0.048, \textcolor{blue}{all of which met the numeric requirement for acceptable goodness-of-fit. I hence took model 4 as a well-fitting model.}
 
\textcolor{blue}{Further, I checked the factor-loading, variance and co-variance residual estimates to evaluate the presence of aberrant parameters. }

```{r}
#print concern table for model 4
concern.table(sem4, 
              nofpath = 14, 
              nofpredictor = 6, 
              "model4")
```

See table 6. \textcolor{blue}{No Heywood case was present any more. Yet, five regression paths were still non-significant (p values were highlighted in red). These paths were then removed from the model. }

(4) Re-specification of model 4 to get baseline model

```{r}
# Modified, restructured baseline model for the calibration data:
model.bl <- 
  model4 |> 
  str_replace_all("F11PA.~.F1ROLA.+.F7SELF.+.F8ELC.+.F9EE.+.F10DP", 
                  " F11PA ~ F7SELF + F9EE + F10DP") |> 
  str_replace_all("F10DP.~.F2ROWO.+.F9EE", 
              " F10DP ~ F9EE") |> 
  str_replace_all("F8ELC.~.F4DEC", 
                  "") |> 
  str_replace_all("F7SELF.~.F4DEC.+.F5SSUP.+.F6PSUP", 
              " F7SELF ~ F4DEC + F5SSUP")

```

### Establish the baseline model for calibration group

(1) Visualize baseline model

```{r, fig.height =  10, fig.width = 14, cache=TRUE}
semPaths(semPlotModel(model.bl),
         style = "lisrel",
         rotation = 2,
         covAtResiduals = F,
         sizeLat = 6,
         sizeLat2 = 5,
         sizeMan = 5,
         sizeMan2 = 2,
         residScale = 4,
         shapeMan = "rectangle",
         edge.color = c(rep("black", 32), #34 
                        rep("blue", 9),
                        rep("steelblue",1),
                        rep("gray", 32),
                        rep("red", 5)), 
         residuals = T,
         layout = m,
         nCharNodes=0,
         optimizeLatRes = T,
         exoVar = F #if exogenous variables also has variance estimated
         )
title(main = list(
  "Figure 8. Baseline model of elementary teacher burnout, modified from model 4",
                  cex = 1.5, font =1
  ),
     outer = F, line = -1)
title(sub = "Notes: Red arrow indicates factor residuals; gray arrow indicates error residuals;
     Blue arrow indicates regression path; black arrow indicates factor loading;
     Covariance between items is highlighted in steelblue",
     line = 1, adj = 0.7)
```

However, given deletion of the paths leading from F11 to F1 and from F6 to F7, together with the fact that there are no specified relations between either F1 or F6 and any of the remaining factors, \textcolor{blue}{it would be more appropriate if F1 and F6 were deleted from the model, for parsimony. The model was hence redefined by removing F1 and F6 and visualized as follows. }

```{r}
# Modified, restructured and simplified baseline model for the calibration data:
model.bl.trim <- '
F1ROWO       =~ ROLEC1 + ROLEC2 + WORK1 + WORK2
F2CLIM       =~ CCLIM1 + CCLIM2 + CCLIM3 + CCLIM4
F3DEC        =~ DEC1 + DEC2
F4SSUP       =~ SSUP1 + SSUP2
F5SELF       =~ SELF1 + SELF2 + SELF3
F6ELC        =~ ELC1 + ELC2 + ELC3 + ELC4 + ELC5
F7EE         =~ EE1 + EE2 + EE3
F8DP         =~ DP1 + DP2
F9PA         =~ PA1 + PA2 + PA3

# Regression paths:
F5SELF        ~ F3DEC + F4SSUP
F6ELC         ~ F1ROWO
F7EE          ~ F1ROWO + F2CLIM
F8DP          ~ F7EE
F9PA          ~ F5SELF + F7EE + F8DP

# Residual covariances:
EE1 ~~ EE2
'
```

```{r}
#redefine the matrix to place the nodes of SEM diagram
m <- matrix(NA, 60, 72)
m[4, 48] <- "ROLEC1"
m[4, 40] <- "ROLEC2"
m[4, 32] <- "WORK1"
m[4, 24] <- "WORK2"
m[4, 16] <- "CCLIM1"
m[5, 10] <- "CCLIM2"
m[10, 4] <- "CCLIM3"
m[15, 4] <- "CCLIM4"
m[20, 4] <- "DEC1"
m[27, 6] <- "DEC2"
m[36, 4] <- "SSUP1"
m[40, 4] <- "SSUP2"
m[48, 32] <- "SELF1"
m[52, 28] <- "SELF2"
m[51, 21] <- "SELF3"
m[56, 50] <- "ELC1"
m[60, 48] <- "ELC2"
m[60, 42] <- "ELC3"
m[60, 35] <- "ELC4"
m[56, 31] <- "ELC5"
m[43, 52] <- "EE1"
m[42, 42] <- "EE2"
m[35, 38] <- "EE3"
m[20, 64] <- "DP1"
m[20, 58] <- "DP2"
m[52, 71] <- "PA1"
m[56, 64] <- "PA2"
m[53, 57] <- "PA3"
m[12, 35] <-"F1ROWO"
m[12,12] <- "F2CLIM"
m[21,12] <-"F3DEC"
m[40,12] <-"F4SSUP"
m[44,24] <-"F5SELF"
m[52,40] <-"F6ELC"
m[37,48] <-"F7EE"
m[26,60] <-"F8DP"
m[48,64] <-"F9PA"
```


```{r, fig.height =  10, fig.width = 14, cache=TRUE}
semPaths(semPlotModel(model.bl.trim),
         style = "lisrel",
         rotation = 2,
         covAtResiduals = F,
         sizeLat = 6,
         sizeLat2 = 5,
         sizeMan = 5,
         sizeMan2 = 2,
         residScale = 4,
         shapeMan = "rectangle",
         edge.color = c(rep("black", 28), #34 
                        rep("blue", 9),
                        rep("steelblue",1),
                        rep("gray", 28),
                        rep("red", 5)), 
         residuals = T,
         layout = m,
         nCharNodes=0,
         optimizeLatRes = T,
         exoVar = F #if exogenous variables also has variance estimated
         )
title(main = list(
  "Figure 9. Streamlined baseline model (with detached factors and the corresponding 
  indicators deleted) of elementary teacher burnout, modified from initial baseline model",
                  cex = 1.5, font =1
  ),
     outer = F, line = -1)
title(sub = "Notes: Red arrow indicates factor residuals; gray arrow indicates error residuals;
     Blue arrow indicates regression path; black arrow indicates factor loading;
     Covariance between items is highlighted in steelblue",
     line = 1, adj = 0.7)
```

(2) Estimate untrimmed and trimmed baseline model for calibration group

```{r}
sem.bl <-   
  sem(
    model.bl,
    data = ele.cali,
    estimator = "MLM",
    mimic = "Mplus"
  )

sem.bl.trim <-   
  sem(
    model.bl.trim,
    data = ele.cali,
    estimator = "MLM",
    mimic = "Mplus"
  )
```

```{r}
# Numerical summary of the model:

sem.bl.fit <-
  cfa.summary.mlm.a(sem.bl) |>
  t() |>
  as.data.frame()

sem.bl.trim.fit <-
  cfa.summary.mlm.a(sem.bl.trim) |>
  t() |>
  as.data.frame()

#combine with preceding fit indices
#baseline model
names(sem.bl.fit) <- sem.bl.fit[1,]
sem.bl.fit <- sem.bl.fit[-1,]
rownames(sem.bl.fit) <- NULL

sem.bl.fit <- 
  sem.bl.fit |> 
  mutate(Model = "Baseline, original§") |> 
  select(Model, everything())
#baseline model trimmed
names(sem.bl.trim.fit) <- sem.bl.trim.fit[1,]#turn 1st row into var names
sem.bl.trim.fit <- sem.bl.trim.fit[-1,]#delete the 1st row
rownames(sem.bl.trim.fit) <- NULL #delete row names

sem.bl.trim.fit <- 
  sem.bl.trim.fit |> 
  mutate(Model = "Baseline, trimmed**") |> 
  select(Model, everything())

#add chi-square difference value
sem.bl.fit$diff <- chi.diff.anova(sem4, sem.bl)
sem.bl.trim.fit$diff <- chi.diff.anova(sem.bl, sem.bl.trim)

sem1234bl.fit <-
  rbind(sem1234.fit,
        sem.bl.fit,
        sem.bl.trim.fit)

#print the table
multi.fit.tab2(
  sem1234bl.fit,
  "Fit indices for calibration dataset, original and trimmed baseline models
               comparing with preceding models",
  c(
    "Model2: Initial model with Factors 3 and 2 combined",
    "Model3: Model2 with parameter F8 on F2 freely estimated",
    "Model4: Model3 with residual covariance between EE1 and EE2 estimated",
    "Baseline, original: Model4 with 5 n.s regression paths deleted",
    "Baseline, trimmed: Original baseline model with detached factors deleted"
  ))
```

See table 7. Though the goodness-of-fit of the baseline model with untrimmed number of factors looked much better than the trimmed one, I still turn to results of the latter. No doubt, it is more sensible to delete factors not involved in the structural paths in case the imprecise number of degree of freedom inflates the goodness of fit. \textcolor{blue}{Results from the last model fitted (Baseline, trimmed) were as follows: chi-square(333) = 726.551, CFI = 0.950, RMSEA = 0.044, and SRMR = 0.051. They looked fairly good. Yet I needed to check its loading/variance/covariance estimates before making final decision.} The table was shown below.

```{r}
#print concern table for model baseline, trimmed
concern.table(sem.bl.trim, model = "baseline model, trimmed") |> 
  row_spec(22, color = "red")
```

See table 8. The parameter estimates yielded good results. None Heywood cases nor non-significant parameters were detected. \textcolor{blue}{However, one residual covariance between F9(PA) and F6(ELC) was estimated despite I did not ask lavaan to do so.} \textcolor{red}{According to the slides, like Mplus, lavvan estimates the residual covariance between final dependent variables by default. In other words, (as I understand) when we do not configure any causal relationship between any pair of dependent variables in our model, lavaan would estimate their covariance, unsolicited. My understanding about this default setting is: it is commonplace that researchers are interested in the how the  their dependent variables (DVs) influence each other in a SEM model. For example, in examining the emotional risk factors to depression (DV1) and Neuroticism (DV2), it is of interest to look at the inter-dependency of DV1 and DV2, and that is why researchers choose to place them in one model. However, in our case, our research interest is to validate a causal structure involving the impact of organizational and personality factors on three facets of burnout for elementary teachers. The priority outcomes are burnout-related indicators. Both organizational and personality aspects are the influencing factors we want to identify, though we assume the latter can also be influenced by the former (external aspects influence the internal aspects). In the process of searching for baseline model, we have allowed the emergence of any possible predictive effects between personality aspects and burnout by checking model modification indices. Yet F6 did not emerge as being an important predictor of F9. Then again, given F6 (a personality aspect) is not of the same level of interest in the study as F9 (one indicator of MBI), we chose to constrain them not to co-vary, for better estimating the MBI-related indicators. Nonetheless, we can also argue for and estimate their covariance, where needed. }

(3) Re-specification of trimmed baseline model

\textcolor{blue}{As discussed above, I further modified the model be constraining the co-variance between F9(PA) and F6(ELC) as zero.} The model was defined as below. Note that in the trimmed baseline model we have already reached an fairly acceptable goodness-of-fit. \textcolor{blue}{Given the current re-specification did involve big modification and also relax one degree of freedom, I would anyway take this model as the final baseline model.  }

```{r}
model.bl.final <-
  paste(model.bl.trim,
        'F6ELC    ~~ 0*F9PA'
        , sep = "\n ")
```


### Estimate and evaluate the final baseline model for calibration group

```{r}
sem.bl.final <-   
  sem(
    model.bl.final,
    data = ele.cali,
    estimator = "MLM",
    mimic = "Mplus"
  )
```

```{r}
# Numerical summary of the model:
sem.bl.final.fit <-
  cfa.summary.mlm.a(sem.bl.final) |>
  t() |>
  as.data.frame()
#baseline model, extract needed values
names(sem.bl.final.fit) <- sem.bl.final.fit[1,]
sem.bl.final.fit <- sem.bl.final.fit[-1,]
rownames(sem.bl.final.fit) <- NULL

sem.bl.final.fit <- 
  sem.bl.final.fit |> 
  mutate(Model = "Baseline, final††") |> 
  select(Model, everything())

#add chi-square difference value
sem.bl.final.fit$diff <- chi.diff.anova(sem.bl.trim, sem.bl.final)
#combine with preceding fit indices
sem1234blf.fit <-
  rbind(sem1234bl.fit,
        sem.bl.final.fit)
#print the table
key.table1 <- multi.fit.tab2(
  sem1234blf.fit,
  "Fit indices for calibration dataset, final baseline model
               comparing with preceding models",
  c(
    "Model2: Initial model with Factors 3 and 2 combined",
    "Model3: Model2 with parameter F8 on F2 freely estimated",
    "Model4: Model3 with residual covariance between EE1 and EE2 estimated",
    "Baseline, original: Model4 with 5 n.s regression paths deleted",
    "Baseline, trimmed: Original baseline model with detached factors deleted",
    "Baseline, final: Preceding model with default estimation of F9/F6 covariance negated"
  ));key.table1
```

See table 9. \textcolor{blue}{This final baseline model, though with one more degree of freedom, yielded basically the same results of fit indices with the trimmed baseline model.} Its parameter estimates also showed nothing to be concerned with. See table 10. 

```{r}
concern.table(sem.bl.final, model = "baseline model, final") 
```

## Form and test the multigroup configural model with no parameter constraints

### Merge the calibration and validation datasets

```{r}
mbi.both <- 
  merge(
    data.frame(
      ele.cali, 
      sample = "calibration"
      ),
    data.frame(
      ele.vali, 
      sample = "validation"
      ),
    all = TRUE, 
    sort = FALSE
    )
```

### Define the configural model

There are no parameter specifications that are relevant only to the calibration group. \textcolor{blue}{The configural model was defined in the same way as final model baseline model had been defined.}

```{r}
model.config <- model.bl.final
```


### Estimate the configural model for merged data sets

The model fit results derived from this model represent a multi-group version of the combined baseline models for calibration and validation data sets.

```{r}
sem.config <- 
  sem(
    model.config, 
    data = mbi.both, 
    estimator = "MLM", 
    group = "sample"
    )
```

```{r}
# Numerical summary of the model:
sem.config.fit <-
  cfa.summary.mlm.a(sem.config) |>
  t() |>
  as.data.frame()

#turn baseline model estimates into data frame
names(sem.config.fit) <- sem.config.fit[1,]
sem.config.fit <- sem.config.fit[-1,]
rownames(sem.config.fit) <- NULL

sem.config.fit <- 
  sem.config.fit |> 
  mutate(Model = "Configural, for both samples") |> 
  select(Model, everything())

#add chi-square difference value
sem.config.fit$diff <- chi.diff.anova(sem.bl.final, sem.config)

#combine with preceding fit indices
model.bl.config <- 
  rbind(sem.bl.final.fit, sem.config.fit)

model.bl.config[1,1] <- "Baseline, for calibration sample"

#extract and convert needed values
model.bl.config.tab <- 
  model.bl.config |> 
  select(
    chisquare = 'chi square',
    p = 'p value',
    everything()
    ) |> 
  mutate(
    df = as.numeric(df) |> round(0),
    chisquare = as.numeric(chisquare),
    p = p |> 
      as.numeric(),
    p =  
      case_when(
        p < 0.001 ~ "<0.001",
        p >= 0.001 ~ as.character(p)
        ),
    chi1 = paste0(
      chisquare,
      "(", 
      df,
      ",",
      p,
      ")")
    ) |> 
  select(
    Model,
    "Chi-square(df, p)" = chi1,
    CFI,
    TLI,
    RMSEA,
    SRMR
    )
#add group-level chi-square values
model.bl.config.tab[3:4,1] <- c("Calibration sample contribution", 
                            "Validation sample contribution")
model.bl.config.tab[3:4,2] <- 
  c(round(sem.config@test[[2]]$stat.group[1],3), 
    round(sem.config@test[[2]]$stat.group[2],3))
#replace NA across the data frame
model.bl.config.tab <- 
  model.bl.config.tab  %>% 
  replace(is.na(.), "--")

key.table2 <- model.bl.config.tab |> 
  kable(linesep= "",
        #format = "markdown",
        booktab = T,
        caption = "Fit indices of configural model (merged sample) 
        comparing to baseline model (calibration sample)") |> 
  kable_styling() |> 
  column_spec(1, width = "5.5cm") |> 
  column_spec(2, width = "3.5cm") |> 
  column_spec(3, width = "0.9cm") |> 
  column_spec(4, width = "0.9cm") |> 
  column_spec(5, width = "1.3cm") |> 
  column_spec(6, width = "1cm") |> 
  add_indent(c(3,4));key.table2
```

See table 11. Model fit for the calibration group (chi-square = 722.373) was slightly better than it was for the validation group (chi = 761.689). Yet, \textcolor{blue}{overall model fit to their combined data yielded goodness-of-fit statistics that were negligibly different from the baseline model}, which had the same specification fitted for calibration group only. More specifically, whereas the CFI, RMSEA, and SRMR values were 0.945, 0.045, and 0.056 respectively, when this model was tested separately for the calibration group, they remained minimally different when tested fro both groups simultaneously.

\textcolor{blue}{Provided with evidence of a well-fitting model for the combined calibration and validation samples, I can now proceed with testing for the equivalence of SEM.}

## Test for the in-variance of structural regression paths across samples. 

### Define the configural model with equaity constraints

\textcolor{blue}{Factor loadings, manifest variable intercepts, structural regressions and factor means were constrained equal across two samples.} If fitted model fit indices do not turn un-negligibly worse comparing with the configural model, conclusion of in-variance of structural regression paths can be drawn across calibration and validation samples. Besides, same model was specified for both samples, and no model-specific components were included in the settings. 

### Estimate the configural model with equaity constraints

```{r}
sem.constr1 <- 
  sem(model.config, 
      data = mbi.both, 
      estimator = "MLM", 
      group = "sample",
      group.equal = c("loadings", 
                      "intercepts",
                      "regressions",
                      "means"),# to reproduce Mplus results
      meanstructure = TRUE)
```


```{r}
# Numerical summary of the model:
sem.constr1.fit <-
  cfa.summary.mlm.a(sem.constr1) |>
  t() |>
  as.data.frame()
#turn baseline model estimates into data frame
names(sem.constr1.fit) <- sem.constr1.fit[1,]
sem.constr1.fit <- sem.constr1.fit[-1,]
rownames(sem.constr1.fit) <- NULL
sem.constr1.fit <- 
  sem.constr1.fit |> 
  mutate(Model = "Contraint Model 1") |> 
  select(Model, everything())
#add chi-square difference value
sem.constr1.fit$diff <- chi.diff.anova(sem.config, sem.constr1)
#combine with preceding fit indices
model.bl.cf.cs <-  #baseline configure constraint
  rbind(model.bl.config, sem.constr1.fit)
#extract and convert needed values
model.bl.cf.cs <- 
  model.bl.cf.cs |> 
  rename(
    chisquare = 'chi square',
    p = 'p value'
    ) |> 
  mutate(
    Model = c("Baseline(calibration)",
              "Configural(both)†",
              "Constraint1(both)‡"),
    df = as.numeric(df) |> round(0),
    chisquare = as.numeric(chisquare),
    p = p |> 
      as.numeric(),
    p =  
      case_when(
        p < 0.001 ~ "<0.001",
        p >= 0.001 ~ as.character(p)
        ),
    chi1 = paste0(
      chisquare,
      "(", 
      df,
      ",",
      p,
      ")")
    ) |> 
  select(
    "Model (sample)"= Model,
    "Chi-square(df, p)" = chi1,
    "ΔChi-square(df,p)*" = diff,
    CFI,
    TLI,
    RMSEA,
    SRMR
    )
model.bl.cf.cs[1,3] <- "--"
#print the table
model.bl.cf.cs |> 
  kable(linesep= "",
        booktab = T,
        caption = "Fit indices of configural model (merged sample) 
        comparing to baseline model (calibration sample)",
        align = "lrrrrrr") |> 
  kable_styling() |> 
  column_spec(1, width = "3.5cm") |>
  column_spec(1, width = "3.3cm") |> 
  column_spec(3, width = "3.3cm") |> 
  column_spec(4, width = "0.8cm") |> 
  column_spec(5, width = "0.8cm") |> 
  column_spec(6, width = "1.3cm") |> 
  column_spec(7, width = "1cm") |> 
  footnote(symbol = 
             c("ΔChi-square by ANOVA() function, comparing with the preceding model",
               "Same specification with the preceding model, but fit for both samples",
               "Structural regressions,etc were constrained equal across two samples"))
```

See table 12. \textcolor{blue}{The goodness-of-fit of the constraint model was exceptionally good and only minimally less optimal than the configural model}, with very slight difference in statistics observing only at the third decimal place, except fo TLI, which even was slightly better than configural model. \textcolor{blue}{This finding was corresponded to the results of ANOVA chi-square difference test, yielding a value of 57.441 (56), or non-significant p of 0.422. }

### Redefine, estimate and evaluate the constraint model by imposing more equaity constraints 

\textcolor{blue}{Since the initial constraint model fitted was exceptionally good, I decided to more strictly examine the in-variance across samples by imposing constraints on factor residual variance and co-variance.}

```{r}
sem.constr2 <- 
  sem(model.config, 
      data = mbi.both, 
      estimator = "MLM", 
      group = "sample",
      group.equal = c("loadings", 
                      "intercepts",
                      "regressions",
                      "means",
                      "lv.variances",
                      "lv.covariances"
                      ),
      meanstructure = TRUE)
```

```{r}
# Numerical summary of the model:
sem.constr2.fit <-
  cfa.summary.mlm.a(sem.constr2) |>
  t() |>
  as.data.frame()
#turn baseline model estimates into data frame
names(sem.constr2.fit) <- sem.constr2.fit[1,]
sem.constr2.fit <- sem.constr2.fit[-1,]
rownames(sem.constr2.fit) <- NULL
sem.constr2.fit <- 
  sem.constr2.fit |> 
  mutate(Model = "Contraint2(both)§") |> 
  select(Model, everything())
#add chi-square difference value
sem.constr2.fit$diff <- chi.diff.anova(sem.config, sem.constr2)
#extract and convert needed values
sem.constr2.fit <- 
  sem.constr2.fit |> 
  rename(
    chisquare = 'chi square',
    p = 'p value'
    ) |> 
  mutate(
    df = as.numeric(df) |> round(0),
    chisquare = as.numeric(chisquare),
    p = p |> 
      as.numeric(),
    p =  
      case_when(
        p < 0.001 ~ "<0.001",
        p >= 0.001 ~ as.character(p)
        ),
    chi1 = paste0(
      chisquare,
      "(", 
      df,
      ",",
      p,
      ")")
    ) |> 
  select(
    "Model (sample)"= Model,
    "Chi-square(df, p)" = chi1,
    "ΔChi-square(df,p)*" = diff,
    CFI,
    TLI,
    RMSEA,
    SRMR
    )
#combine with preceding fit indices
model.cf.cs12 <-  #baseline configure constraint
  rbind(model.bl.cf.cs, sem.constr2.fit)
#remove the first row about baseline model
model.cf.cs12 <- model.cf.cs12[-1,]
model.cf.cs12[1,3] <- "--"
rownames(model.cf.cs12) <- NULL

#print the table
key.table3 <- model.cf.cs12 |> 
  kable(linesep= "",
        #format = "markdown",
        booktab = T,
        caption = "Fit indices of constraint models (merged sample) 
        comparing to configural model (merged sample)",
        align = "lrrrrrr") |> 
  kable_styling() |> 
  column_spec(1, width = "3.5cm") |>
  column_spec(1, width = "3.3cm") |> 
  column_spec(3, width = "3.3cm") |> 
  column_spec(4, width = "0.8cm") |> 
  column_spec(5, width = "0.8cm") |> 
  column_spec(6, width = "1.3cm") |> 
  column_spec(7, width = "1cm") |> 
  footnote(
    symbol =
      c(
        "ΔChi-square by ANOVA() function, always comparing with the configural model",
        "Same specification with the baseline model, but fit for both samples",
        "Structural regressions,etc were constrained equal across two samples",
        "Factor (co)variance were constrained equal, in addition to preceding constraints"
      ))
key.table3
```

See table 13. \textcolor{blue}{The constraint model 2, like constraint model 1, showed fairly good fit indices that were closely approaching the results of configural model, with precisely same CFI, better TL and only minimally less optimal RMSEA and SRMR. The chi-square difference value comparing with configural model was 65.268 at 71 degree of freedom, or a n.s p value of 0.669.}

With these findings and discussions, I can \textcolor{blue}{conclude that these parameters are operating equivalently across calibration and validation samples. Namely, the validity of pos-hoc models of MBI inventory for elementary teachers were further consolidated.}

# Summary of key steps

The purpose of testing calibration/validation sample equivalence is to find evidence for the validity of the post-hoc models established in an exploratory way. I briefly summarized the steps of the testing here, with representative tables cited from preceding texts with new indexing.

a. Split the data into calibration and validation sample.

b. Define an initial model. Use only the calibration sample to estimate it and, when necessary, re-specify the model in searching for a well-fitting, parsimonious model. Table 14 records the process of this journey.

c. When a well-fitting is found, non-significant paths are expected to be removed from model. Subsequently, if the removal leads to any factors detached from all the structural model, it is appropriate to also trim these factors and their corresponding indicators. See the rows 5 and 6 of table 14, which are untrimmed and trimmed models, respectively.

d. Lavaan estimates the residual covariance between dependent variable in the model by default. Need to neutralize this setting manually, if needed. See the last row of table 14.

f. The trimmed well-fitting, parsimonious model will serve as the baseline model. We will then fit the merged datasets (calibration + validation) with this model configuration. This newly fitted model is called configural model. If its goodness-of-fit does not get too far away towards the downside from the baseline model, the configural model is established. We can also examine the difference in fit between validation and calibration datasets, by looking at the contribution of each separate chi-square value to overall chi-square. See table 15.

g. Next, impose the equality constraints of factor loadings, manifest variable intercepts, structural regressions and factor means (could also include latent factor residual variance and covariance) across two samples. If the constrained model does not differ much from the baseline model in terms of fit indices and the result of chi-square difference test, we can conclude that the parameters are operating equivalently across calibration and validation samples.



```{r}
key.table1;key.table2;key.table3
```





