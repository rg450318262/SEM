---
title: "COS-D419 Factor Analysis and Structural Equation Models 2023, Assignment 4"
author: "Rong Guang"
date: "`r Sys.Date()`"
output:
  bookdown::pdf_document2:
    latex_engine: lualatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F, cache = F, fig.align = 'center')
```

**\textcolor{blue}{The texts that reflect my understanding have been highlighted in} \textcolor{red}{red color}.** 

# Task description

The first section is task description, which is copied from the assignment5.rmd. It is for communicating with future "me". Please skip it.

## Exercise 5.1

Specify and estimate the initial baseline models for the two groups. 

Present a brief summary of the model fit and make the first step of the modification by including **(exceptionally, at the same time!)** all the four parameters known to be required for improving the model fit of both models.

Fine-tune the models step by step following the guidelines given in the lecture material, i.e., implement the modifications **(as usually, one change at a time)** testing and studying each step. 

Present the final baseline models of each group and draw the graphs

# Preparation

## Read in the data set:

Start by downloading the **two data files** from Moodle to your Project folder!
xie
```{r}
#install the necessary pakages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(here, 
               expss, 
               tidyverse, 
               janitor,
               knitr, 
               qualtRics, 
               arules, 
               arulesViz, 
               sjlabelled,
               DT,
               stringr,
               labelled,
               ggstatsplot,
               ggcorplot)

library(tidyverse)
library(readr)

#This week's file name
latest.name1 <- "MBIELM1.CSV"
latest.name2 <- "MBISEC1.CSV"
#read in the data
mbi.elm <-  #elementary school
  read_csv(
    file.path(
      here(),
      'data',
      latest.name1
      )
    )

mbi.sec <- #secondary school
  read_csv(
    file.path(
      here(),
      'data',
      latest.name2
      )
    )

```

## Write functions

To control length of reports, codes already shown in the previous homework were not showing in the current report. Yet they are available in .rmd report.

### To generate a function for calculating chi square difference was defined.

```{r, echo = F}
chisq_mlm <- function(fit_nested, fit_parent) {
    # scaling correction factors
      c0 <- fitMeasures(fit_nested, "chisq.scaling.factor") %>% as.numeric()
      c1 <- fitMeasures(fit_parent, "chisq.scaling.factor") %>% as.numeric()
    # scaling correction of the difference test
      d0 <- fitMeasures(fit_nested, "df") %>% as.numeric()
      d1 <- fitMeasures(fit_parent, "df") %>% as.numeric()
      cd <- ((d0 * c0) - (d1 * c1))/(d0 - d1)
    # MLM chi-square difference test
      T0 <- fitMeasures(fit_nested, "chisq.scaled") %>% as.numeric()
      T1 <- fitMeasures(fit_parent, "chisq.scaled") %>% as.numeric()
      TRd <- (T0*c0 - T1*c1)/cd
    # degrees of freedom
      df = d0 - d1
    return(c("TR_d" = TRd |> round(3), 
             "df" = df |> round(0), 
             "p_value" = pchisq(TRd, df, lower.tail = FALSE) |> round(3)))
}
```

### to generate CFA results with improved readability

```{r, echo = F}
#goodness of fit indicators for ml
cfa.summary.mlm.a <- function(fit){
  options(scipen = 999)
  cfa.measure <- fitMeasures(fit,    #obtain specified measured.
                            c("chisq.scaled", 
                              "df.scaled", 
                              "pvalue.scaled", 
                              "cfi.scaled", 
                              "tli.scaled",
                              "rmsea.scaled",
                              "rmsea.pvalue.scaled",
                              "srmr_bentler",
                              "chisq.scaling.factor")) 
  names(cfa.measure) <- c("chi square", "df", "p value", "CFI", "TLI", "RMSEA", "RMSEA p value", "SRMR", "CSF")
  #turn named vector to data frame
cfa.tab.a <- cfa.measure %>%  
  tibble(name= names(cfa.measure), value = cfa.measure) %>% # vector to df
  select(Measure = name, Value = value) %>%  #select and rename columns
  mutate(Value = round(as.numeric(Value),3)) 
}
#factor loading
cfa.summary.b <- function(fit, fa.num, item.num, estimator){
  options(scipen = 999)
  #factor loading
  cfa.tab.b <- parameterEstimates(fit, standardized=TRUE) %>% # obtain estimates
  filter(op == "=~") %>%  #select "is measured by" rows
  mutate(Parameter = paste0(lhs, "→", rhs),
         pvalue = case_when(as.numeric(pvalue)<0.001~"<0.001", 
                            as.numeric(pvalue)>=0.001~as.character(pvalue)
                            )
         ) |> 
  select(Parameter,
         Beta=std.all, #std estimates
         SE=se, #standard error
         Z=z, #z statistics
         'p-value'=pvalue #p value
         ) 
  # %>%  
  # kable(digits = 3, #rounded to 3
  #       format="markdown", #Latex markdown
  #       booktabs=TRUE, #Latex booktabs
  #       caption=paste("Factor Loadings for",fa.num,"factor CFA model estimated by ", estimator)) %>% #caption
  # kable_styling(latex_options = "striped") %>% #gray every other row
  # row_spec(0, background = "#9999CC") # color the first row
  # cfa.tab.b
  }

#Variance
cfa.summary.c <- function(fit, fa.num, item.num, estimator){
  options(scipen = 999)
  #Variance
  type <- rep(c("Residual", "Total"), 
            time = c(item.num, fa.num)) #create a new row clarifying types of variance

variance <- parameterEstimates(fit, standardized=TRUE) %>% #obtain estimates
  filter(op == "~~") #select "is correlated with" rows
variance <- variance[1:sum(item.num,fa.num),] #subset 1:18 rows (variance row)
variance <- cbind(type, variance) #add column
cfa.tab.c <- variance |> 
  mutate(pvalue = case_when(as.numeric(pvalue)<0.001~"<0.001", 
                            as.numeric(pvalue)>=0.001~as.character(pvalue)
                            )) |> 
  select(Parameter = type, #select and rename variables
                   Indicator=rhs, #right hand side column
                   B=est, #estimates
                   "Beta*"=std.all,#std estimates
                   SE=se,#standard error
                   Z=z, #z statistics
                   'p-value'=pvalue #p value
                   ) 

# %>% 
#   kable(digits = 3, #rounded
#         format="markdown",  #Latex markdown
#         booktabs=TRUE, #Latex booktabs
#         caption=paste("Variances for", fa.num, "factor model estimated by ", estimator)) %>% #caption
#   kable_styling(latex_options = "striped") %>% # gray every other row
#   row_spec(0, background = "#9999CC") # color the variable row
#   cfa.tab.c
}

#Covariance
cfa.summary.d <- function(fit, fa.num, item.num, estimator){
  options(scipen = 999)
  #covariance
  variance <- parameterEstimates(fit, standardized=TRUE) %>%
  filter(op == "~~")
  covar.num = (fa.num+(fa.num-1))/2
variance <- variance[sum(item.num,fa.num,1):sum(item.num,fa.num,covar.num),]
type <- paste(variance$lhs, "←→", variance$rhs) 
variance <- cbind(type, variance)
rownames(variance) <- NULL
cfa.tab.d <- variance |> 
  mutate(pvalue = case_when(as.numeric(pvalue)<0.001~"<0.001", 
                            as.numeric(pvalue)>=0.001~as.character(pvalue)
                            )) |> 
  select(Parameter=type,
         B=est, 
         Beta=std.all,
         SE=se,
         Z=z, 
         'p-value'=pvalue 
         )
# %>% 
#   kable(digits = 3, 
#         format="markdown", 
#         booktabs=TRUE, 
#         caption=paste("Covariances for", fa.num, 
#                       "factor model estimated by ", 
#                       estimator)) %>% 
#   kable_styling(latex_options = "striped") %>% 
#   row_spec(0, background = "#9999CC")
#   cfa.tab.d
}

```

### Write a function to simplify plotting of merged tables for multi-group fit indicies

```{r}
multi.fit.tab <- function(data, title, more.footnote = NULL){
data <- data |> 
  rename(p = 'p value',
         p2 = 'RMSEA p value',
         chi = 'chi square') |> 
  mutate(df = as.numeric(df) |> round(0),
         p = case_when(
           as.numeric(p) < 0.001 ~ "<0.001",
           as.numeric(p) >= 0.001 ~ p
           ),
         p2 = case_when(
           as.numeric(p2) < 0.001 ~ "<0.001",
           as.numeric(p2) >= 0.001 ~ p2
           )
         ) |>
  mutate('Chi square (df, p)' = 
           paste0(chi, "(", df,", ", p, ")"),
         'RMSEA(p)'           = 
           paste0(RMSEA, "(", p2, ")"
                  )
         ) |> 
  select(
    Model,
    'Chi square (df, p)', 
    CFI, TLI,
    'RMSEA(p)', 
    SRMR, 
    'CSF*'= CSF
    ) 
#print the combined table with adjustment of aesthetics
data |> 
  kable(booktabs = T, 
        #format = "markdown", 
        caption = 
          title,
        align = "lrrrrrr"
        ) |> 
  kable_styling(full_width = T) |> 
  footnote(symbol = 
             c("Chi square scaling factor", 
               more.footnote)
           ) |>
  column_spec(1, width = "3.5cm") |> 
  column_spec(2, width = "4cm")|> 
  column_spec(3, width = "1cm")|> 
  column_spec(4, width = "1cm")|> 
  column_spec(5, width = "2.5cm")|> 
  column_spec(6, width = "1cm") |> 
  column_spec(7, width = "1cm") 
}
```


### Write a function to simplify plotting of merged tables for multi-group fit indicies with chi square difference statistics

```{r}
delta.fit.tab <- function(data, title, more.footnote = NULL){
  data$'ΔChi-square(df,p)*' <- rep(NA, nrow(data))
  for (i in 2:nrow(data)){
    nested <- paste0("inv", i, ".fit")
    diff<- as.numeric(chisq_mlm(eval(parse(text = nested)), inv1.fit)[1])
    diff.df <-  as.numeric(chisq_mlm(eval(parse(text = nested)), inv1.fit)[2])
    diff.p<- as.numeric(chisq_mlm(eval(parse(text = nested)), inv1.fit)[3])                 
    data$'ΔChi-square(df,p)*'[i] <-  paste0(diff, "(", diff.df,", ", diff.p, ")")
  }
  

data <- data |> 
  rename(p = 'p value',
         p2 = 'RMSEA p value',
         chi = 'chi square') |> 
  mutate(df = as.numeric(df) |> round(0),
         p = case_when(
           as.numeric(p) < 0.001 ~ "<0.001",
           as.numeric(p) >= 0.001 ~ p
           ),
         p2 = case_when(
           as.numeric(p2) < 0.001 ~ "<0.001",
           as.numeric(p2) >= 0.001 ~ p2
           )
         ) |>
  mutate('Chi square (df, p)' = 
           paste0(chi, "(", df,", ", p, ")"),
         'RMSEA(p)'           = 
           paste0(RMSEA, "(", p2, ")"
              )
         ) |> 
  select(
    Model,
    'Chi square (df, p)', 
    'ΔChi-square(df,p)*',
    CFI, TLI,
    'RMSEA(p)', 
    SRMR
    ) 
data[1,3] <- "__"
#print the combined table with adjustment of aesthetics
data |> 
  kable(booktabs = T, 
        #format = "markdown", 
        caption = 
          title,
        align = "lrrrrrr"
        ) |> 
  kable_styling(full_width = T) |> 
  footnote(symbol = 
             c("Chi square differece statistics of model of the row compared to configural model", 
               more.footnote)
           ) |>
  column_spec(1, width = "2.8cm") |> 
  column_spec(2, width = "3.5cm")|> 
  column_spec(3, width = "3cm")|> 
  column_spec(4, width = "1cm")|> 
  column_spec(5, width = "1cm")|> 
  column_spec(6, width = "2.2cm") |> 
  column_spec(7, width = "1cm") 
}

```

### Write a function to simplify plotting aligned residual variance and co-variance tables

```{r}
align.table <- function(data, num.no.header.col, title){

data  |> 
  kable(
    digits = 3,
    booktabs = T,
    #format = "markdown",
    caption = title,
    linesep = ""
    ) |>  
  add_header_above(c(" " = num.no.header.col, 
                     "Elementary level" = 5,
                     "Secondary level" = 5
                     )
                   ) |> 
  kable_styling(
    latex_options = "striped"
  ) |> 
  footnote(
           symbol = c(
             "Un-standardized estimates",
             "Standardized estimates"
                      )
           )
}
```

### Write a function for correlation matrix with numbers

```{r, echo = F}
mymatrix <- function(data, fig.num = 3){
  library(GGally)
ggcorr(data, 
       geom = "blank", 
       label = TRUE, 
       hjust = 0.9, 
       color = "red", 
       face = "bold", 
       method = c("pairwise","pearson"),
       digits = 2,
       size= 2.5,
       label_size = 2.5,
       label_round = 2,
       layout.exp =1) +
  geom_point(size = 7, 
             aes(color = "steelblue", 
                 alpha = abs(coefficient) > 0.3)) +
  scale_alpha_manual(values = c("TRUE" = 0.4, 
                                "FALSE" = 0)) +
    geom_point(size = 8, 
               aes(color = "red", 
                   alpha = abs(coefficient) > 0.6)) +
  scale_alpha_manual(values = c("TRUE" = 0.4, 
                                "FALSE" = 0)) +
  guides(color = FALSE, 
         alpha = FALSE) +
  labs(title = paste("Figure ", fig.num," Pearson correlation matrix of the selected items"),
       caption = 
         " Red circles indicates the absolute of correlation coefficient >= 0.6 
        green circle indicates >= 0.3")+
  theme(plot.title = element_text(size = 12,
                                  face = "bold",
                                  hjust = 0.5),
        plot.caption = element_text(color = "red"))
}

```

### to generate a function for histogram overlapping with density plot

```{r, echo = F}
corr.density <- function(data, fig.num = 1){
  data %>% 
  pivot_longer(everything()) %>%  #longer format
  ggplot(aes(x = value)) + #x axis used variable "value" (a default of pivot)
  geom_histogram(binwidth = 1, aes(y = ..density..), #match ys of density and histogram plots
                 color = "black",  fill = "#9999CC")+  # adjust aesthetics for hist
  geom_density(fill = "pink", alpha = 0.25)+ #adjust aesthetics for density plot
  facet_wrap(~name, scales = "free", ncol =4) + #wrap by name variable
  theme(panel.grid.major = element_blank(), #get rid of the  grids
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white",#adjust the background
                                        color = "black"),
        strip.background = element_rect(color = "black",#adjust the strips aes
                                        fill = "steelblue"),
        strip.text = element_text(size =8, color = "white"), #adjust strip text
        axis.title.x = element_text(size = 3), #adjust the x text
        axis.title.y = element_text(size = 3), # adjust the y text
        plot.title = element_text(size = 12, 
                                  face = "bold",
                                  hjust = 0.5))+ #adjust the title
  labs(title = paste("Figure ", fig.num," Distribution of selected items")) #title it
  }

```

### to generate a function for violin overlapping with box plot

```{r, echo = F}
violin.box <- function(data, fig.num = 2){
  mbi.long <- data %>% pivot_longer(everything(), names_to = "item", values_to = "score")

mbi.long %>% 
  ggplot(aes(x = item, y = score)) +
  geom_violin(trim=F, fill = "#9999CC") +
  theme(legend.position = "none", 
        axis.text.x = element_text(angle = 45, hjust =1),
        axis.title = element_text(size = 12),
        panel.background = element_rect(fill = "white", color = "black"),
        plot.title = element_text(face="bold",
                                  hjust = 0.5),
        axis.title.x = element_blank())+
  labs(x = "Item", 
       y = "Score",
       title = paste("Figure 2 ", fig.num, " Violin plot of the selected items"))+
  geom_boxplot(width = 0.1, fill = "white")
}
```

### To generate a function describing continuous data set

```{r, echo=F}
descriptive <- function(data){
  library(finalfit)
library(kableExtra)
inspect.table <- ff_glimpse(data)$Continuous
inspect.table$label <- NULL
inspect.table %>% 
  mutate('Q1Q3' = paste(quartile_25, 
                        quartile_75, 
                        sep = " ~ ")) %>% 
  select(n, 
         'n of NA' = missing_n, 
         'Mean' = mean, 
         'Median' = median,
         'SD' = sd, 
         'Min' = min, 
         'Max' = max,
         'Q1~Q3' = Q1Q3) %>%
  kable(booktabs = T,  
        align = "r",
        longtable = T,
        linesep = "",
        caption = "Descriptive statistics for measurements") %>% 
  add_header_above(c(" ", 
                     " " = 2,
                     "Central tendency" = 2, 
                     "Dispersion tendency" = 4)) %>% 
  kable_styling(latex_options = c("striped", 
                                  "repeat_header")) %>% 
  column_spec(1, width = "3cm")
}
```

### Write a function describing continuous data set

```{r, echo=F}
descriptive <- function(data){
  library(finalfit)
library(kableExtra)
inspect.table <- ff_glimpse(data)$Continuous
inspect.table$label <- NULL
inspect.table %>%
  mutate('Q1Q3' = paste(quartile_25,
                        quartile_75,
                        sep = " ~ ")) %>%
  select(n,
         'n of NA' = missing_n,
         'Mean' = mean,
         'Median' = median,
         'SD' = sd,
         'Min' = min,
         'Max' = max,
         'Q1~Q3' = Q1Q3) %>%
  kable(booktabs = T,
        align = "r",
        longtable = T,
        linesep = "",
        caption = "Descriptive statistics for measurements") %>%
  add_header_above(c(" ",
                     " " = 2,
                     "Central tendency" = 2,
                     "Dispersion tendency" = 4)) %>%
  kable_styling(latex_options = c("striped",
                                  "repeat_header")) %>%
  column_spec(1, width = "3cm")
}
```

### Write a function for histogram overlapping with density plot

```{r, echo = F}
corr.density <- function(data, fig.num = 1, group){
  data %>%
  pivot_longer(everything()) %>%  #longer format
  ggplot(aes(x = value)) + #x axis used variable "value" (a default of pivot)
  geom_histogram(binwidth = 1, aes(y = ..density..), #match ys of density and histogram plots
                 color = "black",  fill = "#9999CC")+  # adjust aesthetics for hist
  geom_density(fill = "pink", alpha = 0.25)+ #adjust aesthetics for density plot
  facet_wrap(~name, scales = "free", ncol =5) + #wrap by name variable
  theme(panel.grid.major = element_blank(), #get rid of the  grids
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white",#adjust the background
                                        color = "black"),
        strip.background = element_rect(color = "black",#adjust the strips aes
                                        fill = "steelblue"),
        strip.text = element_text(size =8, color = "white"), #adjust strip text
        axis.title.x = element_text(size = 3), #adjust the x text
        axis.title.y = element_text(size = 3), # adjust the y text
        plot.title = element_text(size = 12,
                                  face = "bold",
                                  hjust = 0.5))+ #adjust the title
  labs(title = paste("Figure", fig.num," Distribution of selected items for", group)) #title it
  }
```

### Write a function to generate dot distribution plot

```{r}
dot.dist <- 
  function(data, type, title){
    data |>
      t() |> 
      as.data.frame() %>% 
      mutate(Item = rownames(.)) |> 
      rowwise() |> 
      mutate(Median = eval(parse(text = type))(V1:V580)) |> 
      ggstatsplot::ggdotplotstats(
        point.args = list(color = "red", size = 3, shape = 13),
        xlab = paste(type, "ratings"),
        title = title,
        x = Median,
        y = Item
      )
    }
```

### Write a fuction to generate correlation matrix with statistical test

```{r}
mycor <- 
  function(data, cols, title){
  mbi.elm |> 
      select(all_of(cols)) |> 
      ggstatsplot::ggcorrmat(
        colors = c("#B2182B", "white", "#4D4D4D"),
        title = "(a) Items on emotional exhaustion, 
        elementary school teacher",
        matrix.type  = "lower"
      )
    }
```

# Inspect the data

## Distribution

```{r,fig.width= 8, fig.height = 13}
#generate the plots, by subgroup of teachers
p.dist.elm <- 
  corr.density(
    mbi.elm, 
    fig.num = "1(a)", 
    group = "elementary school teacher"
    )
p.dist.sec <- 
  corr.density(
    mbi.sec, 
    fig.num = "1(b)",
    group = "secondary school teacher"
    )
#print the plot
library(patchwork); p.dist.elm/p.dist.sec
```

 
```{r,fig.width= 8, fig.height = 5}
#generate plot by subgroups of teachers
p.dot.elm <- 
  dot.dist(
    data = mbi.elm, 
    type = "median", 
    title = "(a) Elementary school teacher"
    )
p.dot.sec <- 
  dot.dist(
    data = mbi.sec, 
    type = "median", 
    title = "(b) Secondary school teacher"
    )
#plot layout
patchwork <- p.dot.elm|p.dot.sec
#print the plot with a genral title
patchwork+plot_annotation(
    title = 
      'Figure 2 Distributions of median rating for each item',
    theme = 
      theme(plot.title = 
              element_text(
                size = 16,
                face = "bold",
                vjust = -1.5,
                hjust =0.5)
            )
    )
```


```{r,fig.width= 10, fig.height = 15}
fa.ee <- c("ITEM1", "ITEM3", "ITEM6", "ITEM8", "ITEM13", "ITEM14", "ITEM16", "ITEM20")
fa.dp <- c("ITEM5", "ITEM10", "ITEM11", "ITEM15", "ITEM22")
fa.pa <- c("ITEM4", "ITEM7", "ITEM9", "ITEM12", "ITEM17", "ITEM18", "ITEM19", "ITEM21")
#generate 6 plots, 3 factors X 2 subgroups of teachers
p.cor.elm.ee <- 
       mycor(
         data= mbi.elm, 
         cols = fa.ee, 
         "(a) Items on emotional exhaustion, 
         elementary school teacher"
         )
p.cor.sec.ee <- 
       mycor(
         data = mbi.sec, 
         cols = fa.ee, 
         "(b) Items on emotional exhaustion, 
          secondary school teacher"
         )
p.cor.elm.dp <- 
       mycor(
         data = mbi.elm, 
         cols = fa.dp, 
         "(c) Items on depersonalization,
          elementary school teacher"
         )
p.cor.sec.dp <- 
       mycor(
         data = mbi.sec, 
         cols = fa.dp, 
         "(d) Items on depersonalization,
          secondary school teacher"
         )
p.cor.elm.pa <- 
       mycor(
         data = mbi.elm, 
         cols = fa.pa, 
         "(e) Items on personal accomplishment,
         secondary school teacher"
         )
p.cor.sec.pa <- 
       mycor(
         data = mbi.sec ,
         cols = fa.pa, 
         "(f) Items on personal accomplishment,
          secondary school teacher"
         )
#plot sub-figure layout
patchwork <- 
  p.cor.elm.ee/p.cor.elm.dp/p.cor.elm.pa|p.cor.sec.ee/p.cor.sec.dp/p.cor.sec.pa 
#print the plot with a gernal title
patchwork+
  plot_annotation(
    title = 
      'Figure 3 Correlalogram for items on each factor for two groups of teachers',
    theme = 
      theme(plot.title = 
              element_text(
                size = 16,
                face = "bold",
                vjust = -1.5,
                hjust =0.5)
            )
    )

```

# Testing the factorial invariance of MBI inventory between elementary and secondary school teachers  

## Define and estimate initial models for both subgroups

\textcolor{blue}{The postulated three-factor structure of the MBI that was tested in the previous assignments were re-tested as the initial model for establishing a baseline model. }

### Define the initial model 

```{r}
library(lavaan)
# Define a CFA model using the lavaan (Latent Variable Analysis) syntax:
# see https://lavaan.ugent.be/tutorial/syntax1.html
initial.model <- '
# CFA model for the burnout, the baseline model:
    EE =~ ITEM1 + ITEM2 + ITEM3 + ITEM6 + ITEM8 + 
          ITEM13 + ITEM14 + ITEM16 + ITEM20
    DP =~ ITEM5 + ITEM10 + ITEM11 + ITEM15 +ITEM22
    PA =~ ITEM4 + ITEM7 + ITEM9 + ITEM12 + 
          ITEM17 + ITEM18 + ITEM19 + ITEM21
          '
```

Cited from Byrne: *It is important to note that measuring instruments are often group specific in the way they operate, and, thus, it is possible that baseline models may not be completely identical across groups.*

### Estimate indices to examine factorial validity 

(1) Estimate factorial validity for the elementary teacher subgroup

```{r}
cfa.elm <- 
  cfa(
    initial.model, 
    data = mbi.elm,  
    estimator = "MLM",
    mimic = "Mplus"
    )
```

(2) Estimate factorial validity for the secondary teacher subgroup

```{r}
cfa.sec <- 
  cfa(
    initial.model, 
    data = mbi.sec,  
    estimator = "MLM",
    mimic = "Mplus"
    )
```

### Evaluate model

(1) Fit indices

```{r}
library(knitr);library(kableExtra)
#combine fit indices of both levels
initial.elm.fit <- 
  cfa.summary.mlm.a(cfa.elm) |> 
  t() |> 
  as.data.frame()

initial.sec.fit <- 
  cfa.summary.mlm.a(cfa.sec) |> 
  t() |> 
  as.data.frame()

initial.both <- 
  rbind(
    initial.elm.fit[2,], 
    initial.sec.fit[2,]
    ) 

names(initial.both) <- 
  initial.elm.fit[1,]

rownames(initial.both) <- NULL

initial.both <- 
  initial.both |> 
  mutate(Model = c("Elementary level",
    "Secondary level")) |> 
  select(Model, everything())

#print the table
multi.fit.tab(initial.both, "Fit indices for two subgroups, basline models")
```

\textcolor{blue}{See table 1. Goodness-of-fit statistics for this baseline model (three factor) reveals that the indices are less than optimal for both elementary (MLM Chi-square[206] = 826.573; CFI = 0.857; RMSEA = 0.072 ; SRMR = 0.068) and secondary (MLM Chi-square[206] = 999.359; CFI = 0.836; RMSEA = 0.075; SRMR = 0.077) levels.}

(2) factor loading

Factor loading of elementary level were extracted.

```{r}
fl.elm <- cfa.summary.b (cfa.elm) #fl  is for factor loading)
colnames(fl.elm)[2] <- "Beta*"
```

Factor loading of secondary level were extracted.

```{r}
fl.sec <- cfa.summary.b (cfa.sec) #fl is for factor loading
colnames(fl.sec) <- c("Parameter",
                     "Beta* ",
                     "SE ",
                     "Z ",
                     "p-value ")
```

Factor loading of both levels were merged in one table and printed.

```{r}
fl.both <- left_join(fl.elm, 
                     fl.sec, 
                     by = "Parameter")
fl.both |> 
  kable(
    digits = 3,
    booktabs = T,
    #format = "markdown",
    caption = "Factor loadings for both levels",
    linesep = ""
    ) |>  
  add_header_above(c(" " = 1, 
                     "Elementary level" = 4,
                     "Secondary level" = 4
                     )
                   ) |> 
  kable_styling() |> 
  row_spec(1:9, 
           background = "#E5E4E2"
           ) |> 
  row_spec(15:22, 
           background = "#E5E4E2"
           ) |> 
  row_spec(c(1,10,15), bold = T) |> 
  footnote(general = 
             "Rows with coeffcient estimates fixed to 1 are highligted in bold ",
           symbol = c(
             "Standardized estimates"
                      )
           )
  
```

the cross-loading involved the loading of Item 12 on Factor 1 (Emotional Exhaustion) in addition to its targeted Factor 3 (Personal Accomplishment)

(3) Variance 

Variance of elementary level were extracted.

```{r}
var.elm <- cfa.summary.c(cfa.elm, fa.num = 3, item.num = 22)
names(var.elm)[3] <- "Beta*"
names(var.elm)[4]<- "Beta†"
```

Variance of secondary level were extracted.

```{r}
var.sec <- cfa.summary.c(cfa.sec, fa.num = 3, item.num = 22)
var.sec <- var.sec[,-1]
names(var.sec) <- 
  c("Indicator", 
    "Beta* ", 
    "Beta† ",
    "SE ", 
    "Z ", 
    "p-value "
    )
```

Variance of both levels were merged in one table and printed.

```{r}
var.both <- left_join(var.elm, 
                     var.sec, 
                     by = "Indicator")

align.table(data = var.both, 
            num.no.header.col = 2, 
            title = "Residual variance for both levels")
```

(3) Co-variance

Co-variance of elementary level were extracted.

```{r}
cov.elm <- cfa.summary.d(cfa.elm, fa.num = 3, item.num = 22)
colnames(cov.elm)[2:3] <- c("Beta*", "Beta†")
```

Co-variance of secondary level were extracted.

```{r}
cov.sec <- cfa.summary.d(cfa.sec, fa.num = 3, item.num = 22)
colnames(cov.sec) <- c("Parameter", "Beta* ", "Beta† ", "SE ", "Z ", "p-value ")
```

Co-variance of both levels were merged in one table and printed.

```{r}
cov.both <- left_join(cov.elm, 
                     cov.sec, 
                     by = "Parameter")

align.table(data = cov.both, 
            num.no.header.col = 1, 
            title = "Residual co-variance for both levels")
```

### Model re-specification

(1) Search for mis-specified parameters

\textcolor{blue}{To establish baseline models for both panels of teachers that represent good model fit and parsimony, I further investigated the modification indices of the hypothesized models, respectively for two levels. }

MIs of elementary level panel were calculated.

```{r}
#extract needed variables
initial.MI.elm <- 
  modindices(cfa.elm,
             standardized = TRUE,
             sort. = TRUE,
             maximum.number = 10)
```

MIs of secondary level panel were calculated.

```{r}
#extract needed variables
initial.MI.sec <- 
  modindices(cfa.sec,
             standardized = TRUE,
             sort. = TRUE,
             maximum.number = 10)
```

MI tables with 10 largest MI parameters was printed in descending order of MI. Potential mis-specification of most concerns were highlighted in red.

```{r}
MI.both <- rbind(initial.MI.elm, initial.MI.sec)

MI.both    |> 
  mutate(
    op = case_when(op == "~~"~"←→",
                   op == "=~"~"→"), 
    Parameter = 
           paste(lhs, op, rhs)
         ) |>
  select(Parameter, 
         MI = mi, 
         EPC = epc, 
         "std EPC" = sepc.all
         )|>
  kable(digits = 3,
        booktab = T,
        linesep = "",
        caption = 
          "Selected modification indices for determining baseline model") |>
  kable_styling(
    latex_options = "striped"
    ) |>
  row_spec(
    c(1:4, 11:14), 
    color = "red"
    ) |> 
  footnote(general = 
             "Rows highlighted in red are of special concerns") |> 
  pack_rows(index = c(
    "Elementary level" = 10,
    "Secondary level" = 10
    )
    )
```

\textcolor{blue}{See table 5. Three exceptionally large residual co-variances and one cross-loading contributed to the misfit of the model for both teacher panels. The residual co-variances involved Items 1 and 2, Items 6 and 16, and Items 10 and 11; the cross-loading involved the loading of Item 12 on Factor 1 (Emotional Exhaustion) in addition to its targeted Factor 3 (Personal Accomplishment).}

 In reviewing both the MIs and expected parameter change (EPC) statistics for elementary teachers (table 5, upper part), it is clear that all four parameters are contributing substantially to model misfit, with the residual covariance between Item 6 and Item 16 exhibiting the most profound effect.
 
 We see precisely the same pattern on secondary teachers, albeit the effect would appear to be even more pronounced than it was for elementary teachers. One slight difference between the two groups of teachers regards the impact of these four parameters on model misfit. Whereas the residual covariance between Items 6 and 16 was found to be the most seriously misfitting parameter for elementary teachers; for secondary teachers, the residual covariance between Items 1 and 2 was most pronounced. 

(2) Re-specify initial model to model 2

\textcolor{blue}{The good practice is relaxing one parameter each time. Nonetheless, according to the knowledge derived from our previous work, I included all four mis-specified parameters in a post-hoc model (common to the groups).}

First, the 4 parameters were relaxed in model statement.

```{r}
respecified4 <- 'EE =~ ITEM12
                 ITEM6 ~~ ITEM16
                 ITEM10 ~~ ITEM11
                 ITEM1 ~~ ITEM2
                 '
model2 <- paste(initial.model, respecified4)
```

Then, the model fit were re-estimated for both group, respectively

```{r}
#for elementary
cfa2.elm <- 
  cfa(
    model2, 
    data = mbi.elm,  
    estimator = "MLM",
    mimic = "Mplus"
    )
#for secondary
cfa2.sec <- 
  cfa(
    model2, 
    data = mbi.sec,  
    estimator = "MLM",
    mimic = "Mplus"
    )
```

### Examine Model 2 

(1) Inspect fit indices of model2 (comparing to initial model)

```{r}
#combine fit indices of both levels
model2.elm.fit <- 
  cfa.summary.mlm.a(
    cfa2.elm
    ) |> 
  t() |> 
  as.data.frame()

model2.sec.fit <- 
  cfa.summary.mlm.a(
    cfa2.sec
    ) |> 
  t() |> 
  as.data.frame()

model2.both <- 
  rbind(
    model2.elm.fit[2,], 
    model2.sec.fit[2,]
    ) 

names(model2.both) <- model2.elm.fit[1,]

rownames(model2.both) <- NULL

model2.both <- 
  model2.both |> 
  mutate(Model = c("Elementary level",
    "Secondary level")) |> 
  select(Model, everything())

#combine model 1 and 2 tables
compare12 <- rbind(initial.both, model2.both)

#print the table
multi.fit.tab(compare12, 
              "Fit indices for two subgroups, model 2, comparing to initial model") |> 
  pack_rows(index = c(
    "Initial model" = 2,
    "Model 2" = 2
  )
  )
```

\textcolor{blue}{Estimation of this re-specified model, for each teacher group, yielded greatly improved model fit statistics than initial model. See table 6. However, we should note that several statistics, albeit improved comparing to initial model, still fall below the preferable value. For example, CFI from both groups were <0.95.}

(2) Modification indices of model 2

\textcolor{blue}{To establish baseline models for both panels of teachers that represent good model fit and parsimony, I further investigated the modification indices of model 2, respectively for two groups, to decide if there was any more model mis-fit and mis-specification }

MIs of elementary level panel were calculated.

```{r}
#extract needed variables
model2.MI.elm <- 
  modindices(cfa2.elm,
             standardized = TRUE,
             sort. = TRUE,
             maximum.number = 10)
```

MIs of secondary level panel were calculated.

```{r}
#extract needed variables
model2.MI.sec <- 
  modindices(cfa2.sec,
             standardized = TRUE,
             sort. = TRUE,
             maximum.number = 10)
```

MI tables with 10 largest MI parameters was printed in descending order of MI. Potential mis-specification of most concerns were highlighted in red.

```{r}
MI2.both <- rbind(model2.MI.elm, model2.MI.sec)

MI2.both    |> 
  mutate(
    op = case_when(op == "~~"~"←→",
                   op == "=~"~"→"), 
    Parameter = 
           paste(lhs, op, rhs)
         ) |>
  select(Parameter, 
         MI = mi, 
         EPC = epc, 
         "std EPC" = sepc.all
         )|>
  kable(digits = 3,
        booktab = T,
        linesep = "",
        caption = 
          "Selected modification indices for determining baseline model") |>
  kable_styling(
    latex_options = "striped"
    ) |>
  row_spec(
    c(1:2, 11:12), 
    color = "red"
    ) |> 
  footnote(general = 
             "Rows highlighted in red are of special concerns") |> 
  pack_rows(index = c(
    "Elementary level" = 10,
    "Secondary level" = 10
    )
    )
```

\textcolor{blue}{See table 7. In reviewing this information for elementary teachers, we observe two MIs larger than all other MIs (ITEM7 with ITEM4; ITEM19 with ITEM18); both represent residual co-variances. I followed Byrne's step in addressing these parameters.} According to Byrne, of the two, only the residual covariance between Items 7 and 4 is substantively viable in that there is a clear overlapping of item content. In contrast, the content of Items 19 and 18 exhibits no such redundancy, and, thus, there is no reasonable justification for including this parameter in a succeeding Model 3.

\textcolor{blue}{However, in checking the MI for secondary teachers, the decision was made: more work is needed in establishing an appropriate baseline model.} Two parameters were of special concern due to their large MI and substantive meaningfulness. They are Item 11 cross-loads onto factor EE, and item 19 co-varies with item 9. This time I operated by the good practice of specifying one parameter each time. Given the substantially large MI representing the cross-loading of Item 11 on factor EE, this parameter alone was included in our next post-hoc model (Model 3 for secondary teachers).

Byrne noted the reasons for making this decision (to further re-specifying model secondary teachers), which I quoted here for future reflection: (a) The model does not yet reflect a satisfactorily good fit to the data (CFI = 0.920); and (b) in reviewing the MIs in Table 7.2, we observe one very large mis-specified parameter representing the loading of Item 11 on Factor 1 (F1 by ITEM11), as well as another substantially large MI representing a residual covariance between Items 19 and 9, both of which can be substantiated as substantively meaningful parameters.

(3) Model re-specification of model 2 to model 3

```{r}
respecified3.elm <- 'ITEM4 ~~ ITEM7
                     '
respecified3.sec <- 'EE =~ ITEM11
                     '
model3.elm <- paste(model2, respecified3.elm)                 
model3.sec <- paste(model2, respecified3.sec)
```

Then, the model fit were re-estimated for both group, separately.

```{r}
#for elementary
cfa3.elm <- 
  cfa(
    model3.elm, 
    data = mbi.elm,  
    estimator = "MLM",
    mimic = "Mplus"
    )
#for secondary
cfa3.sec <- 
  cfa(
    model3.sec, 
    data = mbi.sec,  
    estimator = "MLM",
    mimic = "Mplus"
    )
```

### Examine Model 3

(1) Inspect fit indices of model3 (comparing to model 2)

```{r}
#combine fit indices of both levels
model3.elm.fit <- 
  cfa.summary.mlm.a(
    cfa3.elm
    ) |> 
  t() |> 
  as.data.frame()

model3.sec.fit <- 
  cfa.summary.mlm.a(
    cfa3.sec
    ) |> 
  t() |> 
  as.data.frame()

model3.both <- 
  rbind(
    model3.elm.fit[2,], 
    model3.sec.fit[2,]
    ) 

names(model3.both) <- model3.elm.fit[1,]

rownames(model3.both) <- NULL

model3.both <- 
  model3.both |> 
  mutate(Model = c("Elementary level",
    "Secondary level")) |> 
  select(Model, everything())

#combine model 1 and 2 tables
compare123 <- rbind(initial.both, model2.both, model3.both)

#print the table
multi.fit.tab(compare123, 
              "Fit indices for two subgroups, model 3, comparing to preceding models") |> 
  pack_rows(index = c(
    "Initial model" = 2,
    "Model 2" = 2,
    "Model 3" =2
  )
  )
```

See table 8. Results from the estimation of Model 3 for elementary teachers yielded goodness-of-fit statistics that represented a satisfactorily good fit to the data (MLM chi square[201] = 451.061; CFI = 0.942; RMSEA = 0.046; SRMR = 0.049). Although a review of Table 9 (find below) reveals several additional moderately large MIs, for balancing goodness-of-fit and parsimony, \textcolor{blue}{the decision was model 3 can serve as the baseline model for elementary teachers.}

Results from the estimation of Model 3 for secondary teachers, on the other hand, further substantiated the residual covariance between Items 19 and 9 as representing an acutely mis-specified parameter in the model. \textcolor{blue}{Thus, for secondary teachers only, model 4 was put to the test with this residual covariance specified as a freely estimated parameter.}

(2) Modification indices of model 3

MIs of model 3 for each groups were calculated.

```{r}
#elementary
model3.MI.elm <- 
  modindices(cfa3.elm,
             standardized = TRUE,
             sort. = TRUE,
             maximum.number = 10)
#secondary
model3.MI.sec <- 
  modindices(cfa3.sec,
             standardized = TRUE,
             sort. = TRUE,
             maximum.number = 10)
```


MI tables with 10 largest MI parameters was printed in descending order of MI. Potential mis-specification of most concerns were highlighted in red.

```{r}
MI3.both <- rbind(model3.MI.elm, model3.MI.sec)

MI3.both    |> 
  mutate(
    op = case_when(op == "~~"~"←→",
                   op == "=~"~"→"), 
    Parameter = 
           paste(lhs, op, rhs)
         ) |>
  select(Parameter, 
         MI = mi, 
         EPC = epc, 
         "std EPC" = sepc.all
         )|>
  kable(digits = 3,
        booktab = T,
        linesep = "",
        caption = 
          "Selected modification indices for determining baseline model") |>
  kable_styling(
    latex_options = "striped"
    ) |>
  row_spec(
    c(1:2, 11), 
    color = "red"
    ) |> 
  footnote(general = 
             "Rows highlighted in red are of special concerns") |> 
  pack_rows(index = c(
    "Elementary level" = 10,
    "Secondary level" = 10
    )
    )
```

(3) Re-specification of model 3 to model 4 (only for secondary teacher)

The parameter ITEM9 ~~ ITEM19 was relaxed for estimation.

```{r}
respecified4.sec <- 'ITEM9 ~~ ITEM19
                 '
model4.sec <- paste(model3.sec, respecified4.sec)
```

Then, the model fit were re-estimated for secondary group, only

```{r}
cfa4.sec <- 
  cfa(
    model4.sec, 
    data = mbi.sec,  
    estimator = "MLM",
    mimic = "Mplus"
    )
```

### Examine Model 4

\textcolor{blue}{Note that at this point I had taken model 3 as the baseline model for elementary teachers, and model 4 was to achieve the baseline model for secondary teachers.}

(1) Inspect fit indices of model4 (comparing to 3)

```{r}
model4.sec.fit <- 
  cfa.summary.mlm.a(
    cfa4.sec
    ) |> 
  t() |> 
  as.data.frame()

names(model4.sec.fit ) <- model4.sec.fit[1,]

model4.sec.fit <- model4.sec.fit [-1,]
model4.sec.fit  <- 
  model4.sec.fit  |> 
  mutate(Model = "Secondary level") |> 
  select(Model, everything())

rownames(model4.sec.fit ) <- NULL

#combine model 1 and 2 tables
model3.both[1,1] <- "Elementary level†"
model4.sec.fit[1,1] <- "Secondary level‡"
compare1234 <- 
  rbind(initial.both,
        model2.both, 
        model3.both, 
        model4.sec.fit )

#print the table
multi.fit.tab(compare1234, 
              "Fit indices for two subgroups, model 4, comparing to preceding models",
              c("Baseline model for elementary teachers", 
                "Baseline model for secondary teachers")) |> 
  pack_rows(index = c(
    "Initial model" = 2,
    "Model 2" = 2,
    "Model 3" =2,
    "Model 4" =1
  )
  ) |> 
  row_spec(c(5,7), 
           color = "red"
           )
```

\textcolor{blue}{See table 10. Based on a moderately satisfactory goodness-of-fit (MLM cgi-square[200] = 505.831; CFI = 0.937; RMSEA = 0.047; SRMR = 0.052) and to balance fit with parsimony, I consider Model 4 as the final baseline model for secondary teachers. }

```{r}
cfa3.elm <- 
  cfa(
    model3.elm, 
    data = mbi.elm,  
    estimator = "MLM"
    #mimic = "Mplus"
    )

cfa4.sec <- 
  cfa(
    model4.sec, 
    data = mbi.elm,  
    estimator = "MLM"
    #mimic = "Mplus"
    )
```

### Visualize the final baseline models for each group

```{r, fig.width= 9, fig.height= 12, fig.align='center'}
library(semPlot)
grps <- list(EE = c("ITEM1", "ITEM2", "ITEM3", "ITEM6", "ITEM8", 
        "ITEM13", "ITEM14",  "ITEM16", "ITEM20"), 
        DP = c("ITEM5", "ITEM10", "ITEM11", "ITEM15","ITEM22"),
        PA = c("ITEM4", "ITEM7", "ITEM9", "ITEM12",
               "ITEM17", "ITEM18", "ITEM19", "ITEM21"))

order.manifest <- c("ITEM4", "ITEM7", "ITEM9", "ITEM12",
        "ITEM17", "ITEM18", "ITEM19", "ITEM21",
        "ITEM5", "ITEM10", "ITEM11", "ITEM15","ITEM22",
        "ITEM1", "ITEM2", "ITEM3", "ITEM6", "ITEM8", 
        "ITEM13", "ITEM14",  "ITEM16", "ITEM20")

order.latent <- c("PA", "DP", "EE")
par(mfrow=c(1,2))

semPaths(cfa3.elm, 
         "col", #un-weighted edges
         "no", #edge label is standarized
         reorder = F,
         latents = order.latent,
         manifest = order.manifest,
         sizeLat = 8,
         sizeLat2 = 5,
         sizeMan = 6,
         sizeMan2 = 3,
         curveAdjacent = "cov", # if edge for adjacent nodes curly or not, "reg"
         shapeMan = "rectangle",
         style = "lisrel",
         group = "latent",
         curve = 0.3,
         curvature = 0.1,#theme = "colorblind",#cardinal = "lat cov",
         curvePivot = F,# curly edge or not
         rotation = 2,
         color = c("#c68642", "#58668b", "#8874a3"),#edge.color = "steelblue",
         shapeLat = "ellipse",
         label.font = 2,
         label.color = "white", #Label.scale =T,
         label.prop = 0.7
         )
title(main = list("Elementary School Teachers",
                  cex = 1, font =1),outer = F, line = -3)
semPaths(cfa4.sec, 
         "col", #un-weighted edges
         "no", #edge label is standarized
         reorder = F,
         latents = order.latent,
         manifest = order.manifest,
         sizeLat = 8,
         sizeLat2 = 5,
         sizeMan = 6,
         sizeMan2 = 3,
         curveAdjacent = "cov", #if edge for adjacent nodes curly or not, "reg"
         shapeMan = "rectangle",
         style = "lisrel",
         group = "latent",
         curve = 0.3,
         curvature = 0.1,#theme = "colorblind", #cardinal = "lat cov",
         curvePivot = F, # curly edge or not
         layout = "tree",
         rotation = 2,
         color = c("#c68642", "#58668b", "#8874a3"), #edge.color = "steelblue",
         shapeLat = "ellipse",
         label.font = 2,
         label.color = "white",#Label.scale =T,
         label.prop = 0.7
         )
title(main = list("Secondary School Teachers",
                  cex = 1, font =1), outer = F, line = -3)
mtext("Figure 1 Hypothesized configural model", cex = 1.5, side = 1, line = -5, outer = TRUE)
```

\textcolor{blue}{The the plot of baseline model for each group of teachers was created. See pciture 1}  There are three parameters (two residual co-variances [Item 4 with Item 7; Item 9 with Item 19] and one cross-loading [Item 11 on F1]) that were not part of the originally postulated model and that differ across the two groups of teachers. They have the same number of factors and the same factor-loading pattern (\textcolor{red} {A question: Is there any standard for such a pattern? The current baseline models have one cross-loading that differs across the groups so they are not exactaly same.})

# Testing factorial equivalence of MBI between elementary and secondary shcool teachers

\textcolor{blue}{With the baseline models established through the previous steps, I could combine them to generate a common baseline model for both group, or configural model, which bridges the baseline model and the final task--testing factorial in-variance across groups.}

## Establish configural model (inv1.model)

### Combine the datasets

```{r}
mbi.both <- 
  merge(
    data.frame(
      mbi.elm, 
      group = "elementary"
      ),
    data.frame(
      mbi.sec, 
      group = "secondary"
      ),
    all = TRUE, 
    sort = FALSE
    )
```

### Define the configural model

 No equality constraints are imposed for this model. 

```{r}
inv1.model <- '
    EE =~ 1*ITEM1 + ITEM2 + ITEM3 + ITEM6 + ITEM8 + ITEM13 + ITEM14 + ITEM16 + ITEM20
    DP =~ 1*ITEM5 + ITEM10 + ITEM11 + ITEM15 + ITEM22
    PA =~ 1*ITEM4 + ITEM7 + ITEM9 + ITEM12 + ITEM17 + ITEM18 + ITEM19 + ITEM21

# Common modifications (from baseline models built above)
    EE =~ ITEM12 # common cross-loading
 ITEM1 ~~ ITEM2  # common residual covariances (3)
 ITEM6 ~~ ITEM16
ITEM10 ~~ ITEM11

# Group-specific parameters for elementary teachers:
 ITEM4 ~~ c(NA, 0)*ITEM7  # specific residual covariance

# Group-specific parameters for secondary teachers:
    EE =~ c(0, NA)*ITEM11 # specific cross-loading
 ITEM9 ~~ c(0, NA)*ITEM19 # specific residual covariance
'
```

### Estimate the configural model

The model fit results derived from this model represent a multi-group version of the combined baseline models for elementary and secondary teacher. 

```{r}
inv1.fit <- 
  cfa(
    inv1.model, 
    data = mbi.both, 
    estimator = "MLM", 
    group = "group"
    )
```

### Summarize the results

```{r}
#extract the key indicators
inv1.fit.indices <- 
  cfa.summary.mlm.a(inv1.fit) |> 
  t() |> 
  as.data.frame()

#define column and row names for the indicator table
names(inv1.fit.indices) <- inv1.fit.indices[1,]
inv1.fit.indices <- inv1.fit.indices[-1,]
rownames(inv1.fit.indices) <- NULL
inv1.fit.indices$Model <-"Configural (inv1)"

#print the table
multi.fit.tab(
  inv1.fit.indices, 
  "Fit indices for the configural model (inv1.model)"
  )
```

See table 11. Results for this configural model (inv1.model) were as follows: MLM chi-square(401) = 939.696, CFI = 0.939, RMSEA = 0.046, and SRMR = 0.051.

## Impose equality constraints on factor loadings of configural model

### Constrain common factor loadings equal step by step(inv2.model)

(1) Define and inspect the fit indices of model 2 (inv2.model)

\textcolor{blue}{All the common factor loadings were constrained equal across groups. If the results show significant improvement from configural model, we get the evidence about multi-group in-variance. If not, we need to further explore which parameter(s) bring about the difference observed. }

```{r}
inv2.fit <- 
  cfa(inv1.model, 
      data = mbi.both, 
      estimator = "MLM", 
      group = "group",
      group.equal = c("loadings"),
      group.partial = c("EE =~ ITEM11")
  )
```

```{r}
#extract the key indicators
inv2.fit.indices <- 
  cfa.summary.mlm.a(inv2.fit) |> 
  t() |> 
  as.data.frame()

#define column and row names for the indicator table
names(inv2.fit.indices) <- inv2.fit.indices[1,]
inv2.fit.indices <- inv2.fit.indices[-1,]
rownames(inv2.fit.indices) <- NULL
inv2.fit.indices$Model <-"Model2 (inv2)†"

#merge configural model and inv2.model.
fit.indices.12 <- # 12 is for inv1 and inv 2
  rbind(
    inv1.fit.indices, 
    inv2.fit.indices
    ) 

#print the table
multi.fit.tab(
  fit.indices.12, 
  "Comparison Fit indices between the configural model (inv1.model) and model 2 (inv2.model)",
  "Configural model + 20 common factor loadings constrained equal across groups"
  )
```

See table 12. As indicated by the very slightly higher MLM chi-square value (939.696→995.433) and lower CFI value (0.939→0.935), compared with the configural model, results suggest that the model does not fit the data quite as well as it did with no factor-loading constraints imposed. \textcolor{blue}{Thus, we explore furhter to find out the parammeter(s) brought about the non-invariance. }

(2) Examine the modification indices for inv2.model

MIs of inv2.model were calculated. In seeking evidence of non-invariance, we focus only on the factor loadings that were constrained equal across the groups. In addition, in testing for invariance, only those parameters that were constrained equal, are of relevance. Hence, only the parameter statement that meets these requirements were extracted.

First, to simplify the searching for relevant parameters, I defined an object including all parameters were relevant, so that what parameters were shown in MI table were automatically controlled. 

```{r}
#create the parameter statements of relevancy
itemset1 <- "ITEM1 + ITEM2 + ITEM3 + ITEM6 + ITEM8 + ITEM13 + ITEM14 + ITEM16 + ITEM20 + ITEM12"
itemset2 <- "ITEM5 + ITEM10 + ITEM11 + ITEM15 + ITEM22"
itemset3 <- "ITEM4 + ITEM7 + ITEM9 + ITEM12 + ITEM17 + ITEM18 + ITEM19 + ITEM21"
#create relevant statement for EE
relevant.items1 <- 
  stringr::str_replace_all(
    stringr::str_split_1(itemset1, "\\+" ), 
    " ", 
    ""
    ) 
relevant.items1 <- 
  paste("EE", "→", relevant.items1)
#create relevant statement for DP
relevant.items2 <- 
  stringr::str_replace_all(
    stringr::str_split_1(itemset2, "\\+" ), 
    " ", 
    ""
    ) 
relevant.items2 <- 
  paste("DP", "→", relevant.items2)
#create relevant statement for PA
relevant.items3 <- 
  stringr::str_replace_all(
    stringr::str_split_1(itemset3, "\\+" ), 
    " ", 
    ""
    ) 
relevant.items3 <- 
  paste("PA", "→", relevant.items3)
#combine the above into one 
relevant.items <- c(relevant.items1, relevant.items2, relevant.items3)
```

Next, I extract MI table with relevant parameters.

```{r}
inv2.model.MI <- modindices(inv2.fit, 
           standardized = TRUE, 
           minimum.value = 3.84, 
           free.remove = FALSE,
           op = "=~", 
           sort. = TRUE) |> 
  mutate(Parameter = paste(lhs, "→", rhs)) |> 
  filter(Parameter %in% relevant.items) |> 
  arrange(group)
```

Then, MI tables with relevant parameters was printed in descending order of MI. Potential parameters that are very possibly undermining equivalence across elementary and secondary teachers were highlighted in red.

```{r}
inv2.model.MI.elm <- 
  inv2.model.MI  |> 
  filter(group == 1) |> 
  select(Parameter, 
         MI = mi, 
         EPC = epc, 
         "std EPC" = sepc.all
         )

inv2.model.MI.sec <- 
  inv2.model.MI  |>  
  filter(group == 2) |> 
  select(Parameter, 
         MI = mi, 
         EPC = epc, 
         "std EPC" = sepc.all
         )


rbind(inv2.model.MI.elm, inv2.model.MI.sec) |> 
  kable(digits = 3,
        booktab = T,
        linesep = "",
        caption = 
          "Selected modification indices for inv2.model") |>
  kable_styling(
    latex_options = "striped"
    ) |>
  pack_rows(index = c("Elementary teachers" = nrow(inv2.model.MI.elm),
                      "Secondary teachers" = nrow(inv2.model.MI.sec)
                      )
            )|>
  row_spec(
    c(1,3), 
    color = "red"
    ) |> 
  footnote(general = 
             "Rows highlighted in red are of special concerns") 
```

\textcolor{blue}{See table 13. Of all the eligible parameters, the factor loading of Item 11 on DP appears to be the most problematic in terms of its equivalence across elementary and secondary teachers. I relaxed this factor loading(Item 11 by DP) for establishing the the next model, model3 (inv3.model)}

(3) Re-specify model2 to fit model 3 (inv3.model)

```{r}
inv3.fit <- 
  cfa(inv1.model, 
      data = mbi.both, 
      estimator = "MLM", 
      group = "group",
      group.equal = c("loadings"),
      group.partial = c(#"EE =~ ITEM11",
                        "DP =~ ITEM11"
                        )
  )
```

### Constrain common factor loadings equal step by step(inv3.model)

(1) Inspect fit indices of model 3 (inv3.model)

```{r}
#extract the key indicators
inv3.fit.indices <- 
  cfa.summary.mlm.a(inv3.fit) |> 
  t() |> 
  as.data.frame()

#define column and row names for the indicator table
names(inv3.fit.indices) <- inv3.fit.indices[1,]
inv3.fit.indices <- inv3.fit.indices[-1,]
rownames(inv3.fit.indices) <- NULL
inv3.fit.indices$Model <-"Model3 (inv3)‡"

#merge configural model and inv2.model.
fit.indices.123 <- # 123 is for inv1, 2 and 3 models
  rbind(
    inv1.fit.indices, 
    inv2.fit.indices,
    inv3.fit.indices
    ) 

#print the table
delta.fit.tab(fit.indices.123, 
              "Comparison Fit indices across the inv1.model through inv3.model",
              c("Configural model + 20 common factor loadings constrained equal across groups",
                "Inv2.model + a parameter(DP By Item11) set relaxed"))
```

\textcolor{blue} {The fit statistics of inv3.model: MLM chi-square[420] 969.990, CFI 0.937, RMSEA 0.045, SRMR 0.054. The difference in model fit between InvModel 3 and and the configural model (InvModel 1) is, though not significiant, approaching to significance at 0.05 level (p = 0.057). Hence, I decide to make further improvment to the model}

\textcolor{red} {In this step, my results were substantially different from the slides. Here in the slides the p value should be 0.048, base on which the decision was that we should make further improvement. Yet, I got a insiginificant p already. I tried several different possibilities. I found if I set "group.partial = c("DP =~ ITEM11")" instead of "group.partial = c("EE =~ ITEM11","DP =~ ITEM11" )" , I would have seen a significant p value very close to the slides. Yet the degree of freedom would turn to 421 instead of 420. I suppose there should be something I have done wrong. }
 
(2) Examine the modification indices for inv3.model

I extract MI table with relevant parameters.

```{r}
inv3.model.MI <- modindices(inv3.fit, 
           standardized = TRUE, 
           minimum.value = 3.84, 
           free.remove = FALSE,
           op = "=~", 
           sort. = TRUE) |> 
  mutate(Parameter = paste(lhs, "→", rhs)) |> 
  filter(Parameter %in% relevant.items) |> 
  arrange(group)
```

Then, MI tables with relevant parameters was printed in descending order of MI. 

```{r}
inv3.model.MI.elm <- 
  inv3.model.MI  |> 
  filter(group == 1) |> 
  select(Parameter, 
         MI = mi, 
         EPC = epc, 
         "std EPC" = sepc.all
         )

inv3.model.MI.sec <- 
  inv3.model.MI  |>  
  filter(group == 2) |> 
  select(Parameter, 
         MI = mi, 
         EPC = epc, 
         "std EPC" = sepc.all
         )


rbind(inv3.model.MI.elm, inv3.model.MI.sec) |> 
  kable(digits = 3,
        booktab = T,
        linesep = "",
        caption = 
          "Selected modification indices for inv3.model") |>
  kable_styling(
    latex_options = "striped"
    ) |>
  pack_rows(index = c("Elementary teachers" = nrow(inv3.model.MI.elm),
                      "Secondary teachers" = nrow(inv3.model.MI.sec)
                      )
            )|>
  row_spec(
    c(1:2), 
    color = "red"
    ) |> 
  footnote(general = 
             "Rows highlighted in red are of special concerns") 
```
Potential parameters that are very possibly undermining equivalence across elementary and secondary teachers were highlighted in red. \textcolor{blue}{Actually, other than DP measured by ITEM5, none of the other parameters were both of concern and present simultaneously in two groups. I only had one candidate. }

\textcolor{red} {In this step AGAIN, my results were dramatically inconsistent with the slides, I was not able to get the parameter "DP measured by Item15" in the MI table. }

(3) Re-specify model2 to fit model 3 (inv3.model)

```{r}
inv4.fit <- 
  cfa(inv1.model, 
      data = mbi.both, 
      estimator = "MLM", 
      group = "group",
      group.equal = c("loadings"),
      group.partial = c("EE =~ ITEM11",
                        "DP =~ ITEM11",
                        "DP =~ ITEM5"
                        ))

```


### Constrain common factor loadings equal step by step(inv4.model)

(1) Inspect fit indices of model 3 (inv4.model)

```{r}
#extract the key indicators
inv4.fit.indices <- 
  cfa.summary.mlm.a(inv4.fit) |> 
  t() |> 
  as.data.frame()

#define column and row names for the indicator table
names(inv4.fit.indices) <- inv4.fit.indices[1,]
inv4.fit.indices <- inv4.fit.indices[-1,]
rownames(inv4.fit.indices) <- NULL
inv4.fit.indices$Model <-"Model4 (inv4)**"

#merge configural model and inv2.model.
fit.indices.1234 <- # 123 is for inv1, 2, 3 and 4 models
  rbind(
    inv1.fit.indices, 
    inv2.fit.indices,
    inv3.fit.indices,
    inv4.fit.indices
    ) 

#print the table
delta.fit.tab(fit.indices.1234, 
              "Comparison Fit indices across the inv1.model through inv3.model",
              c("Configural model + 20 common factor loadings constrained equal across groups",
                "Inv2.model + a parameter(DP By Item11) set relaxed",
                "Inv3.model + a parameter(DP By Item5) set relaxed"))
```

```{r}
```


```{r}
```


```{r}
```


```{r}
```


```{r}
```


```{r}
```


```{r}
```


```{r}
```

(1) Inspect fit indices of model 3 (inv3.model)
(2) Examine the modification indices for inv3.model
(3) Re-specify model2 to fit model 3 (inv3.model)

```{r}
```
xie

```{r}
inv1.fit.indices <- 
  cfa.summary.mlm.a(inv1.fit) |> 
  t() |> 
  as.data.frame()

initial.sec.fit <- 
  cfa.summary.mlm.a(cfa.sec) |> 
  t() |> 
  as.data.frame()

initial.both <- 
  rbind(
    initial.elm.fit[2,], 
    initial.sec.fit[2,]
    ) 

names(initial.both) <- 
  initial.elm.fit[1,]

rownames(initial.both) <- NULL

initial.both <- 
  initial.both |> 
  mutate(Model = c("Elementary level",
    "Secondary level")) |> 
  select(Model, everything())

#print the table
multi.fit.tab(initial.both, "Fit indices for two subgroups, basline models")
```
```



```{r}
```


```{r}
```


```{r}
```


```{r}
```


```{r}
```




```{r}
```


```{r}
```


```{r}
```


```{r}
```


```{r}
```


```{r}
```


```{r}
```


```{r}
```


```{r}
```


```{r}
```


```{r}
```


```{r}
```


```{r}
```

